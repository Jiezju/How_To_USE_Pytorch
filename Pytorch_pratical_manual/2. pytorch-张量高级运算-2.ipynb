{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量高级操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 张量的拼接与合并操作**\n",
    "\n",
    "    torch.cat(tensor, dim=0, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    将张量按维度dim进行拼接\n",
    "\n",
    "- tensors\n",
    "\n",
    "    张量序列\n",
    " \n",
    "- dim\n",
    "\n",
    "    要拼接的维度\n",
    "    \n",
    "\n",
    "    torch.stack(tensors, dim=0, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    在新创建的维度上dim进行拼接\n",
    "\n",
    "\n",
    "- 注意\n",
    "\n",
    "    cat不改变张量的维度，即合并以后，向量是向量，矩阵是矩阵\n",
    "    \n",
    "    stack会扩充一维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:02:12.864841Z",
     "start_time": "2020-04-18T09:02:07.588528Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 1 =======================================\n",
    "# torch.cat\n",
    "\n",
    "t = torch.ones((2, 3))\n",
    "print(t.shape)\n",
    "t_ca = torch.cat([t, t], dim=0)\n",
    "print(t_ca.shape)\n",
    "t_ca1 = torch.cat([t, t], dim=1)\n",
    "print(t_ca1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "torch.Size([4, 5, 2])\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 2 =======================================\n",
    "# torch.stack\n",
    "\n",
    "t = torch.zeros((4, 5))\n",
    "print(t.shape)\n",
    "t_st = torch.stack([t, t], dim=2) ##在非指定维度上shape必须一致\n",
    "print(t_st.shape)\n",
    "print(t_st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 张量切分**\n",
    "\n",
    "    torch.chunk(input, chunks, dim=0)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    将张量按维度dim进行平均切分\n",
    "    \n",
    "    \n",
    "- input\n",
    "    \n",
    "    要切分的张量\n",
    "\n",
    "- chunks\n",
    "\n",
    "    要切分的份数\n",
    "\n",
    "- dim \n",
    "\n",
    "    要切分的维度\n",
    "    \n",
    "- 输出\n",
    "\n",
    "    张量列表\n",
    "\n",
    "\n",
    "    torch.split(tensor, split_size_or_sections, dim=0)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    将张量按维度dim进行切分\n",
    "\n",
    "- tensor\n",
    "\n",
    "    要切分的张量\n",
    "\n",
    "- split_size_or_sections\n",
    "\n",
    "    指定切分的tensor在dim维的长度，可以为int或list\n",
    "\n",
    "- dim\n",
    "\n",
    "    切分的维度\n",
    "    \n",
    "- 输出\n",
    "\n",
    "    张量列表\n",
    "\n",
    "区分：\n",
    "- torch.split()对于随意切分更为强大\n",
    "- torch.chunk()对于平均切分更为强大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([2, 4])\n",
      "(tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]), tensor([[1., 1., 1., 1.]]))\n",
      "(tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]), tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]]))\n",
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 3 =======================================\n",
    "# torch.chunk\n",
    "\n",
    "t = torch.ones((3, 4))\n",
    "print(t.shape)\n",
    "t_1 = torch.chunk(t, 2, dim=0)\n",
    "print(t_1[0].shape)\n",
    "print(t_1)\n",
    "\n",
    "t_2 = torch.chunk(t, 2, dim=1)\n",
    "print(t_2)\n",
    "print(t_2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个张量：tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "维度为：torch.Size([2, 2])\n",
      "第2个张量：tensor([[1.],\n",
      "        [1.]])\n",
      "维度为：torch.Size([2, 1])\n",
      "第3个张量：tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "维度为：torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 4 =======================================\n",
    "# torch.split\n",
    "\n",
    "t = torch.ones((2, 5))\n",
    "\n",
    "list_of_tensors = torch.split(t, [2, 1, 2], dim=1)\n",
    "\n",
    "for idx, t in enumerate(list_of_tensors):\n",
    "    print(\"第{}个张量：{}\\n维度为：{}\".format(idx + 1, t, t.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 张量索引**\n",
    "\n",
    "    torch.index_select(input, dim, index, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    在维度dim上，按index索引数据\n",
    "    \n",
    "- input\n",
    "    \n",
    "    要索引的张量\n",
    "\n",
    "- index\n",
    "\n",
    "    要索引数据的序号(此处必须为张量)\n",
    "    \n",
    "- 输出\n",
    "\n",
    "    根据索引的张量拼接成新张量\n",
    "\n",
    "总结：\n",
    "\n",
    "- 按维度切分索引重组张量\n",
    "\n",
    "\n",
    "    torch.masked_select(input, mask, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    按mask的True值进行索引\n",
    "\n",
    "- input\n",
    "\n",
    "    索引的张量\n",
    "\n",
    "- mask\n",
    "\n",
    "    与input相同大小的布尔型张量\n",
    "\n",
    "- 输出\n",
    "\n",
    "    一维张量\n",
    "\n",
    "\n",
    "    torch.take(input,index)\n",
    "    \n",
    " - 功能\n",
    " \n",
    "     将input拉成一维后，依据index索引\n",
    "\n",
    "**总结：**\n",
    "\n",
    "- 该方法常用来筛选数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:03:47.217388Z",
     "start_time": "2020-04-18T09:03:46.714312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 2, 0],\n",
      "        [3, 3, 7],\n",
      "        [7, 1, 0]])\n",
      "tensor([[7, 2, 0],\n",
      "        [7, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 5 =======================================\n",
    "# torch.index_select\n",
    "\n",
    "t = torch.randint(0, 9, (3, 3))\n",
    "print(t)\n",
    "idx = torch.tensor([0, 2], dtype=torch.long)  # 注意必须是long类型\n",
    "t_out = torch.index_select(t, dim=0, index=idx)\n",
    "print(t_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:04:17.885207Z",
     "start_time": "2020-04-18T09:04:17.726497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 3, 0],\n",
      "        [3, 8, 6],\n",
      "        [2, 3, 2]])\n",
      "tensor([[ True,  True,  True],\n",
      "        [ True, False, False],\n",
      "        [ True,  True,  True]])\n",
      "tensor([5, 3, 0, 3, 2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 6 =======================================\n",
    "# torch.masked_select\n",
    "\n",
    "t = torch.randint(0, 9, (3, 3))\n",
    "print(t)\n",
    "mask = t.le(5)  ##ge:大于等于 gt：大于  le：小于等于  lt:小于\n",
    "print(mask)\n",
    "t_out = torch.masked_select(t, mask)\n",
    "print(t_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T09:04:40.303692Z",
     "start_time": "2020-04-18T09:04:40.293718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 3, 0, 3, 2, 3, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.masked_select(t, t <= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T07:49:14.682711Z",
     "start_time": "2019-12-26T07:49:14.646791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 6，ex =======================================\n",
    "# torch.take()\n",
    "\n",
    "input_tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "out = torch.take(input_tensor, torch.tensor([1, 2, 4]))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 张量变换**\n",
    "\n",
    "    torch.reshape(input__, shape)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    变换张量形状\n",
    "\n",
    "注意：\n",
    "- 生成的新张量与input共享内存\n",
    "\n",
    "- 同 torch.view(shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T07:41:55.550616Z",
     "start_time": "2019-12-26T07:41:55.498462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor:tensor([2, 1, 4, 5, 3, 0])\n",
      "shape:torch.Size([6])\n",
      "tensor:tensor([[2, 1, 4],\n",
      "        [5, 3, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 4],\n",
       "        [5, 3, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======================================= example 7 =======================================\n",
    "# torch.reshape\n",
    "\n",
    "t = torch.randperm(6)\n",
    "print(\"tensor:{}\\nshape:{}\".format(t, t.shape))\n",
    "t_new = torch.reshape(t, (2, 3))\n",
    "print(\"tensor:{}\".format(t_new, t_new.shape))\n",
    "\n",
    "t.reshape(2,3)##pytorch支持reshape操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.transpose(input, dim0, dim1)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    交换张量的两个维度\n",
    "    \n",
    "- 维度交换\n",
    "\n",
    "    dim0与dim1的交换\n",
    "    \n",
    "        \n",
    "    torch.t(input)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    矩阵转置\n",
    "    \n",
    "- input\n",
    "\n",
    "    输入张量\n",
    "\n",
    "    \n",
    "    torch.permute(shape)\n",
    "    \n",
    " - 功能\n",
    " \n",
    "     交换多维度数据\n",
    "     \n",
    "- shape\n",
    "\n",
    "    交换维度索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_new:tensor([[[0.4810, 0.1906, 0.2812, 0.0878],\n",
      "         [0.5002, 0.2034, 0.0218, 0.4748]],\n",
      "\n",
      "        [[0.8578, 0.5265, 0.4688, 0.2204],\n",
      "         [0.2340, 0.2548, 0.9366, 0.8606]],\n",
      "\n",
      "        [[0.8620, 0.5528, 0.3955, 0.8683],\n",
      "         [0.5050, 0.7317, 0.6520, 0.4701]]])\n",
      "t.shape:torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 8 =======================================\n",
    "# torch.transpose\n",
    "\n",
    "t = torch.rand((2, 3, 4))\n",
    "\n",
    "t_new = t.transpose(0, 1)  #交换第0维和第1维\n",
    "#t_new = torch.transpose(t, 0, 1)\n",
    "print(\"t_new:{}\\nt.shape:{}\".format(t_new, t_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T13:16:41.363511Z",
     "start_time": "2019-12-26T13:16:41.356530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 28, 28, 3])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 8 =======================================\n",
    "# torch.permute(shape)\n",
    "\n",
    "ta = torch.rand(4, 3, 28, 28)\n",
    "t_per = ta.permute(0, 2, 3, 1)\n",
    "print(t_per.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.squeeze(input, dim=None, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    压缩长度为1的维度\n",
    "    \n",
    "- dim\n",
    "\n",
    "    若为None,移除所有长度为1的维度；若指定维度，则该维度为1时才能被移除\n",
    "\n",
    "       \n",
    "    torch.unsqueeze(input, dim, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    按给定的dim扩展维度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_new:torch.Size([2, 3, 4])\n",
      "t_new1:torch.Size([2, 3, 4, 1])\n",
      "-------------------------------------------------\n",
      "t_new:torch.Size([1, 1, 2, 3, 4, 1])\n",
      "t_new3:torch.Size([1, 2, 1, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 9 =======================================\n",
    "# torch.squeeze\n",
    "\n",
    "##压缩维度\n",
    "t = torch.rand((1, 2, 3, 4, 1))\n",
    "t_new = torch.squeeze(t)\n",
    "t_new1 = torch.squeeze(t, 0)\n",
    "print(\"t_new:{}\\nt_new1:{}\".format(t_new.shape, t_new1.shape))\n",
    "print(\"-------------------------------------------------\")\n",
    "##扩展维度\n",
    "#t_new2 = torch.unsqueeze(t)  报错\n",
    "t_new2 = torch.unsqueeze(t, 0)\n",
    "t_new3 = torch.unsqueeze(t, 2)\n",
    "#t_new3.squeeze(1)\n",
    "print(\"t_new:{}\\nt_new3:{}\".format(t_new2.shape, t_new3.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T09:17:58.334866Z",
     "start_time": "2019-12-26T09:17:58.321900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3088, 0.9499, 0.0301, 0.5402, 0.8294, 0.7973, 0.1331, 0.6130, 0.0182,\n",
      "        0.7742, 0.4424, 0.0331, 0.7472, 0.2194, 0.1493, 0.7731, 0.0331, 0.6624,\n",
      "        0.7383, 0.1993, 0.8565, 0.2723, 0.6428, 0.3015, 0.8910, 0.9328, 0.2901,\n",
      "        0.6332, 0.5741, 0.5167, 0.8041, 0.3521])\n",
      "torch.Size([32])\n",
      "torch.Size([1, 32, 1, 1])\n",
      "tensor([[[[0.3088]],\n",
      "\n",
      "         [[0.9499]],\n",
      "\n",
      "         [[0.0301]],\n",
      "\n",
      "         [[0.5402]],\n",
      "\n",
      "         [[0.8294]],\n",
      "\n",
      "         [[0.7973]],\n",
      "\n",
      "         [[0.1331]],\n",
      "\n",
      "         [[0.6130]],\n",
      "\n",
      "         [[0.0182]],\n",
      "\n",
      "         [[0.7742]],\n",
      "\n",
      "         [[0.4424]],\n",
      "\n",
      "         [[0.0331]],\n",
      "\n",
      "         [[0.7472]],\n",
      "\n",
      "         [[0.2194]],\n",
      "\n",
      "         [[0.1493]],\n",
      "\n",
      "         [[0.7731]],\n",
      "\n",
      "         [[0.0331]],\n",
      "\n",
      "         [[0.6624]],\n",
      "\n",
      "         [[0.7383]],\n",
      "\n",
      "         [[0.1993]],\n",
      "\n",
      "         [[0.8565]],\n",
      "\n",
      "         [[0.2723]],\n",
      "\n",
      "         [[0.6428]],\n",
      "\n",
      "         [[0.3015]],\n",
      "\n",
      "         [[0.8910]],\n",
      "\n",
      "         [[0.9328]],\n",
      "\n",
      "         [[0.2901]],\n",
      "\n",
      "         [[0.6332]],\n",
      "\n",
      "         [[0.5741]],\n",
      "\n",
      "         [[0.5167]],\n",
      "\n",
      "         [[0.8041]],\n",
      "\n",
      "         [[0.3521]]]])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "实例：图像每个channel的像素加入同一偏置\n",
    "'''\n",
    "\n",
    "bias = torch.rand(32)  ##行向量\n",
    "print(bias)\n",
    "print(bias.shape)\n",
    "\n",
    "feature_map = torch.rand((4, 32, 14, 14))\n",
    "bias = bias.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "print(bias.shape)\n",
    "print(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    tensor.expand(shape)\n",
    " \n",
    "- 功能\n",
    "\n",
    "    通过复制数据，常用扩展数据方法\n",
    "    \n",
    "    \n",
    "    tensor.repeat(shape)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    复制数据扩展维度，shape为复制的倍数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T12:42:39.723999Z",
     "start_time": "2019-12-26T12:42:39.710010Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.1221]],\n",
      "\n",
      "         [[0.9505]],\n",
      "\n",
      "         [[0.4238]],\n",
      "\n",
      "         [[0.7995]],\n",
      "\n",
      "         [[0.8554]],\n",
      "\n",
      "         [[0.7853]],\n",
      "\n",
      "         [[0.2167]],\n",
      "\n",
      "         [[0.1125]]]])\n",
      "tensor([[[[0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221]],\n",
      "\n",
      "         [[0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505]],\n",
      "\n",
      "         [[0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238]],\n",
      "\n",
      "         [[0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995]],\n",
      "\n",
      "         [[0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554]],\n",
      "\n",
      "         [[0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853]],\n",
      "\n",
      "         [[0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167]],\n",
      "\n",
      "         [[0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125]]],\n",
      "\n",
      "\n",
      "        [[[0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221]],\n",
      "\n",
      "         [[0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505]],\n",
      "\n",
      "         [[0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238]],\n",
      "\n",
      "         [[0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995]],\n",
      "\n",
      "         [[0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554]],\n",
      "\n",
      "         [[0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853]],\n",
      "\n",
      "         [[0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167]],\n",
      "\n",
      "         [[0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125]]],\n",
      "\n",
      "\n",
      "        [[[0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221]],\n",
      "\n",
      "         [[0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505]],\n",
      "\n",
      "         [[0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238]],\n",
      "\n",
      "         [[0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995]],\n",
      "\n",
      "         [[0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554]],\n",
      "\n",
      "         [[0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853]],\n",
      "\n",
      "         [[0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167]],\n",
      "\n",
      "         [[0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125]]],\n",
      "\n",
      "\n",
      "        [[[0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221],\n",
      "          [0.1221, 0.1221, 0.1221, 0.1221]],\n",
      "\n",
      "         [[0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505],\n",
      "          [0.9505, 0.9505, 0.9505, 0.9505]],\n",
      "\n",
      "         [[0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238],\n",
      "          [0.4238, 0.4238, 0.4238, 0.4238]],\n",
      "\n",
      "         [[0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995],\n",
      "          [0.7995, 0.7995, 0.7995, 0.7995]],\n",
      "\n",
      "         [[0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554],\n",
      "          [0.8554, 0.8554, 0.8554, 0.8554]],\n",
      "\n",
      "         [[0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853],\n",
      "          [0.7853, 0.7853, 0.7853, 0.7853]],\n",
      "\n",
      "         [[0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167],\n",
      "          [0.2167, 0.2167, 0.2167, 0.2167]],\n",
      "\n",
      "         [[0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125],\n",
      "          [0.1125, 0.1125, 0.1125, 0.1125]]]])\n",
      "torch.Size([1, 8, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 9 =======================================\n",
    "# tensor.expand(shape)\n",
    "\n",
    "t1 = torch.rand(1, 8, 1, 1)\n",
    "print(t1)\n",
    "tb = t1.expand(4, 8, 4, 4)  ## 仅限于原维度是1的地方\n",
    "print(tb)\n",
    "tc = t1.expand(-1, 8, 6, -1)  ## 默认维度\n",
    "print(tc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T12:51:16.115833Z",
     "start_time": "2019-12-26T12:51:16.007150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 1, 1])\n",
      "torch.Size([2, 1024, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 9 =======================================\n",
    "# tensor.repeat(shape)\n",
    "\n",
    "t1=torch.rand(1,32,1,1)\n",
    "print(t1.shape)\n",
    "t2=t1.repeat(2,32,1,3)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的数学运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加法**\n",
    "\n",
    "    torch.add()  ## a+b\n",
    "\n",
    "**减法**\n",
    "\n",
    "    torch.sub()   ## -\n",
    "\n",
    "**除法**\n",
    "\n",
    "    torch.div()   ## /\n",
    "\n",
    "**乘法**\n",
    "\n",
    "    torch.mul()   ## *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以加法为例：\n",
    "\n",
    "    torch.add(input, alpha=1, other, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    逐元素计算input+alpha*other\n",
    "    \n",
    "- other\n",
    "\n",
    "    另一个张量\n",
    "    \n",
    "     \n",
    "     torch.addcmul(input, value, tensor1, tensor2, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    计算input+value\\*tensor1\\*tensor2\n",
    "    \n",
    "     \n",
    "     torch.addcdiv(input, value, tensor1, tensor2, out=None)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    计算input+value\\*tensor1/tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_0:tensor([[8, 1, 5],\n",
      "        [2, 1, 0],\n",
      "        [0, 0, 4]])\n",
      "t_1:tensor([[3, 3, 3],\n",
      "        [3, 3, 3],\n",
      "        [3, 3, 3]])\n",
      "t_result:tensor([[11,  4,  8],\n",
      "        [ 5,  4,  3],\n",
      "        [ 3,  3,  7]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 8 =======================================\n",
    "# torch.add\n",
    "\n",
    "t_0 = torch.randint(0, 9, (3, 3))\n",
    "t_1 = torch.full_like(t_0, 3)\n",
    "print(\"t_0:{}\\nt_1:{}\".format(t_0, t_1))\n",
    "\n",
    "t_result = torch.add(t_0, t_1)\n",
    "#t_result = torch.add(t_0, 1, t_1)\n",
    "print(\"t_result:{}\".format(t_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.matmul(a,b)\n",
    "    \n",
    "- 功能\n",
    "\n",
    "    矩阵乘法\n",
    "    \n",
    "    \n",
    "    a@b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-26T22:51:31.090623Z",
     "start_time": "2019-12-26T22:51:30.360363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[6., 6.],\n",
      "        [6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 8 =======================================\n",
    "# torch.matmul\n",
    "\n",
    "a=torch.full((2,2),3)\n",
    "print(a)\n",
    "b=torch.ones(2,2)\n",
    "print(b)\n",
    "print(torch.matmul(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对数运算运算**\n",
    "\n",
    "    torch.log(input, out=None)\n",
    "\n",
    "    torch.log10(input)\n",
    "\n",
    "    torch.log2(input)\n",
    "\n",
    "    torch.exp(input)\n",
    "\n",
    "    torch.pow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T06:38:45.781480Z",
     "start_time": "2019-12-28T06:38:45.672761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n",
      "tensor([[8103.0840, 8103.0840],\n",
      "        [8103.0840, 8103.0840]])\n",
      "tensor([[9., 9.],\n",
      "        [9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example 8 =======================================\n",
    "# =============== pow\n",
    "\n",
    "a = torch.full((2, 2), 3)\n",
    "print(a)\n",
    "a.pow_(2)  # 加引号表示原地操作\n",
    "print(a)\n",
    "a.exp_()\n",
    "print(a)\n",
    "a.log_()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**近似计算**\n",
    "\n",
    "    floor \n",
    "    ceil\n",
    "    trunc ##整数 \n",
    "    frac  ##小数\n",
    "    round ##四舍五入\n",
    "    clamp(min,max)  ##将数据限制在min和max之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T06:45:27.822488Z",
     "start_time": "2019-12-28T06:45:27.794596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(2,3)\n",
    "a.floor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T06:45:33.049107Z",
     "start_time": "2019-12-28T06:45:33.042126Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.trunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T06:45:49.946979Z",
     "start_time": "2019-12-28T06:45:49.941957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T06:46:04.277234Z",
     "start_time": "2019-12-28T06:46:04.272250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2237, 0.4241, 0.6359],\n",
       "        [0.5164, 0.8182, 0.6305]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.frac()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T06:48:07.848010Z",
     "start_time": "2019-12-28T06:48:07.842062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2237, 0.4241, 0.5000],\n",
       "        [0.5000, 0.5000, 0.5000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.clamp(0.2,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**三角函数运算**\n",
    "\n",
    "    torch.abs(input)\n",
    "\n",
    "    torch.cos(input)\n",
    "\n",
    "    torch.acos(input)\n",
    "\n",
    "    torch.sin(input)\n",
    "\n",
    "    torch.asin(input)\n",
    "\n",
    "    torch.tan(input)\n",
    "\n",
    "    torch.atan(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 张量统计运算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    norm()  \n",
    "        范数运算\n",
    "    \n",
    "    mean()   sum()        prod()  累乘\n",
    "    \n",
    "    max()    min()   取最大最小\n",
    "    \n",
    "    argmax()   argmin()   取最大最小索引\n",
    "    \n",
    "    kthvalue()   topk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T07:20:26.293734Z",
     "start_time": "2019-12-28T07:20:26.174053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor(8.)\n",
      "tensor(2.8284)\n",
      "tensor([2., 2., 2., 2.])\n",
      "tensor([2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example =======================================\n",
    "# =============== norm\n",
    "\n",
    "t1 = torch.full([8], 1).view(1, 8)\n",
    "t2 = t1.view(2, 4)\n",
    "print(t1)\n",
    "print(t2)\n",
    "\n",
    "print(t1.norm(1))  ## 1范数\n",
    "print(t1.norm(2))  ## 2范数\n",
    "print(t2.norm(1, dim=0))\n",
    "print(t2.norm(2, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T07:33:39.460401Z",
     "start_time": "2019-12-28T07:33:39.336733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.) tensor(3.5000) tensor(7.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example =======================================\n",
    "# =============== a.sum(),a.mean(),a.max(),a.prod()\n",
    "a = torch.arange(8).view(2, 4).float()\n",
    "print(a.sum(), a.mean(), a.max(), a.prod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T07:55:55.143573Z",
     "start_time": "2019-12-28T07:55:55.135594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3.],\n",
      "        [4., 5., 6., 7.]])\n",
      "tensor(7) tensor(0)\n",
      "tensor([1, 1, 1, 1])\n",
      "tensor([0, 0])\n",
      "(tensor([3., 7.]), tensor([3, 3]))\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example =======================================\n",
    "# =============== a.argmax(),a.argmin()\n",
    "print(a)\n",
    "print(a.argmax(), a.argmin())  # 拉平一维后的索引\n",
    "print(a.argmax(dim=0))\n",
    "print(a.argmin(dim=1))\n",
    "print(a.max(dim=1))  #既返回最大值又返回最值索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T08:04:56.472186Z",
     "start_time": "2019-12-28T08:04:56.466197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[3.],\n",
      "        [7.]]), tensor([[3],\n",
      "        [3]]))\n",
      "torch.Size([2, 4])\n",
      "torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# ======================================= example =======================================\n",
    "# =============== keepdim  保证向量，矩阵，张量的dim\n",
    "b = a.max(dim=1, keepdim=True)\n",
    "print(b)\n",
    "print(a.shape)\n",
    "print(b[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    前k个最大\n",
    "    topk(k,dim=0,argest=True)  \n",
    "        - argest=True表示最大\n",
    "    \n",
    "    第k个最大\n",
    "    kthvalue(k,dim=0,argest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:24:38.498819Z",
     "start_time": "2020-03-10T17:24:38.378115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5])\n",
      "(tensor([[0.8951, 0.6925, 0.6097, 0.5674, 0.4667],\n",
      "        [0.9740, 0.8699, 0.8377, 0.8263, 0.6641],\n",
      "        [0.9107, 0.8429, 0.6788, 0.6717, 0.6648],\n",
      "        [0.9699, 0.9376, 0.9242, 0.8082, 0.7893]]), tensor([[2, 4, 9, 3, 1],\n",
      "        [1, 5, 2, 0, 8],\n",
      "        [4, 1, 8, 3, 2],\n",
      "        [3, 1, 6, 4, 9]]))\n"
     ]
    }
   ],
   "source": [
    "# ======================================= 实例返回 top-5 类别=======================================\n",
    "# =============== topk\n",
    "\n",
    "imgdata = torch.rand(4, 10)\n",
    "label = imgdata.topk(5, dim=1)\n",
    "print(label[0].shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-10T17:24:21.934154Z",
     "start_time": "2020-03-10T17:24:21.437964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.3376, 0.3876, 0.1701, 0.1607]), tensor([9, 9, 8, 2]))\n"
     ]
    }
   ],
   "source": [
    "# ======================================= 实例返回 top-5 类别=======================================\n",
    "# =============== topk\n",
    "\n",
    "imgdata = torch.rand(4, 10)\n",
    "label = imgdata.kthvalue(5, dim=1)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
