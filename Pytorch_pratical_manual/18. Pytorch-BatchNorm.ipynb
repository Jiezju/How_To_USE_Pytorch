{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**内涵**\n",
    "\n",
    "- 批\n",
    "\n",
    "    mini-batch\n",
    "\n",
    "- 标准化\n",
    "\n",
    "    0均值 1方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T12:21:14.304543Z",
     "start_time": "2020-05-07T12:21:08.273259Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**批量归一化的类型**\n",
    "\n",
    "![](./img/batch.png)\n",
    "\n",
    "**总览**\n",
    "\n",
    "![](./nb.jpg)\n",
    "\n",
    "**解释**\n",
    "\n",
    "- Batch_Norm\n",
    "\n",
    "         以特征层为单位，计算所有batch_size内的均值与方差，并标准化特征层(即以N为尺度计算均值方差)\n",
    "         \n",
    "- Layer_Norm\n",
    "\n",
    "        以每个特征层元素为单位，计算特征层内所有元素的均值与方差，并标准化（即以H*W为尺度计算均值与方差）\n",
    "\n",
    "- Instance_Norm\n",
    "\n",
    "        逐通道计算均值与方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果把特征图比喻成一摞书，总共有 N 个样本，每个样本有 C 个通道，每个通道层有 H 行，每行 有W 个像素。\n",
    "\n",
    "1. BN 求均值时，把所有样本按通道对应加起来，再除以N×H×W，导致每个通道一个均值和方差，共有C个\n",
    "\n",
    "2. LN 求均值时，把每个样本中的像素值全加起来，再除以C×H×W，导致每个样本有一个均值和方差，共有N个\n",
    "\n",
    "3. IN 求均值时，忽略样本，把每个通道里的所有值相加，除以H×W，使得每个通道有个均值和方差\n",
    "\n",
    "4. GN 求均值时，将样本的通道分组，求出每个组的均值和方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BatchNorm原理**\n",
    "\n",
    "![](./img/batchnorm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN层的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:12:48.720888Z",
     "start_time": "2020-05-06T14:12:48.714891Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers=100):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False) for i in range(layers)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(neural_num) for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for (i, linear), bn in zip(enumerate(self.linears), self.bns):\n",
    "            x = linear(x)\n",
    "            # x = bn(x)\n",
    "            x = torch.relu(x)\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(\"output is nan in {} layers\".format(i))\n",
    "                break\n",
    "\n",
    "            print(\"layers:{}, mean:{}\".format(i, x.std().item()))\n",
    "\n",
    "        return x\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "\n",
    "                # method 1\n",
    "                # nn.init.normal_(m.weight.data, std=1)    # normal: mean=0, std=1\n",
    "\n",
    "                # method 2 kaiming\n",
    "                nn.init.kaiming_normal_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:12:49.575369Z",
     "start_time": "2020-05-06T14:12:49.167461Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers:0, mean:0.8383101224899292\n",
      "layers:1, mean:0.810845136642456\n",
      "layers:2, mean:0.8057557940483093\n",
      "layers:3, mean:0.8525007963180542\n",
      "layers:4, mean:0.838342010974884\n",
      "layers:5, mean:0.7958686947822571\n",
      "layers:6, mean:0.8045035004615784\n",
      "layers:7, mean:0.8100224137306213\n",
      "layers:8, mean:0.7280009984970093\n",
      "layers:9, mean:0.7112995982170105\n",
      "layers:10, mean:0.7215366363525391\n",
      "layers:11, mean:0.769201397895813\n",
      "layers:12, mean:0.7079854011535645\n",
      "layers:13, mean:0.7077028155326843\n",
      "layers:14, mean:0.6731024384498596\n",
      "layers:15, mean:0.6838957071304321\n",
      "layers:16, mean:0.659018874168396\n",
      "layers:17, mean:0.6689760684967041\n",
      "layers:18, mean:0.7156397104263306\n",
      "layers:19, mean:0.7458699941635132\n",
      "layers:20, mean:0.7870975136756897\n",
      "layers:21, mean:0.7753603458404541\n",
      "layers:22, mean:0.7260276079177856\n",
      "layers:23, mean:0.7045286893844604\n",
      "layers:24, mean:0.5795301198959351\n",
      "layers:25, mean:0.6172888278961182\n",
      "layers:26, mean:0.6577270030975342\n",
      "layers:27, mean:0.5839077830314636\n",
      "layers:28, mean:0.5290199518203735\n",
      "layers:29, mean:0.5742870569229126\n",
      "layers:30, mean:0.5316797494888306\n",
      "layers:31, mean:0.5032860636711121\n",
      "layers:32, mean:0.5001125931739807\n",
      "layers:33, mean:0.47506406903266907\n",
      "layers:34, mean:0.47033169865608215\n",
      "layers:35, mean:0.43256279826164246\n",
      "layers:36, mean:0.41797730326652527\n",
      "layers:37, mean:0.467710018157959\n",
      "layers:38, mean:0.4721713960170746\n",
      "layers:39, mean:0.48324283957481384\n",
      "layers:40, mean:0.5042651891708374\n",
      "layers:41, mean:0.5153628587722778\n",
      "layers:42, mean:0.5232030153274536\n",
      "layers:43, mean:0.5366235971450806\n",
      "layers:44, mean:0.5701718926429749\n",
      "layers:45, mean:0.5849481821060181\n",
      "layers:46, mean:0.5516625642776489\n",
      "layers:47, mean:0.5705501437187195\n",
      "layers:48, mean:0.5496993064880371\n",
      "layers:49, mean:0.5872140526771545\n",
      "layers:50, mean:0.532505989074707\n",
      "layers:51, mean:0.4973726272583008\n",
      "layers:52, mean:0.508100152015686\n",
      "layers:53, mean:0.514503538608551\n",
      "layers:54, mean:0.47663596272468567\n",
      "layers:55, mean:0.45550790429115295\n",
      "layers:56, mean:0.46899300813674927\n",
      "layers:57, mean:0.43863457441329956\n",
      "layers:58, mean:0.47407296299934387\n",
      "layers:59, mean:0.44854027032852173\n",
      "layers:60, mean:0.45372816920280457\n",
      "layers:61, mean:0.4642591178417206\n",
      "layers:62, mean:0.4256533086299896\n",
      "layers:63, mean:0.44244036078453064\n",
      "layers:64, mean:0.42928680777549744\n",
      "layers:65, mean:0.40055200457572937\n",
      "layers:66, mean:0.43104758858680725\n",
      "layers:67, mean:0.46056947112083435\n",
      "layers:68, mean:0.427995502948761\n",
      "layers:69, mean:0.43869373202323914\n",
      "layers:70, mean:0.4004141688346863\n",
      "layers:71, mean:0.37726035714149475\n",
      "layers:72, mean:0.3971415162086487\n",
      "layers:73, mean:0.40192604064941406\n",
      "layers:74, mean:0.4137982428073883\n",
      "layers:75, mean:0.4269498884677887\n",
      "layers:76, mean:0.39067912101745605\n",
      "layers:77, mean:0.36198773980140686\n",
      "layers:78, mean:0.38210615515708923\n",
      "layers:79, mean:0.37230733036994934\n",
      "layers:80, mean:0.3692297041416168\n",
      "layers:81, mean:0.3539907932281494\n",
      "layers:82, mean:0.35018518567085266\n",
      "layers:83, mean:0.3340548872947693\n",
      "layers:84, mean:0.35507726669311523\n",
      "layers:85, mean:0.379610538482666\n",
      "layers:86, mean:0.4092038869857788\n",
      "layers:87, mean:0.368564248085022\n",
      "layers:88, mean:0.3328620195388794\n",
      "layers:89, mean:0.33832529187202454\n",
      "layers:90, mean:0.32292765378952026\n",
      "layers:91, mean:0.2908785939216614\n",
      "layers:92, mean:0.26711055636405945\n",
      "layers:93, mean:0.2731684148311615\n",
      "layers:94, mean:0.2681244909763336\n",
      "layers:95, mean:0.23769082129001617\n",
      "layers:96, mean:0.23283152282238007\n",
      "layers:97, mean:0.21676504611968994\n",
      "layers:98, mean:0.22189994156360626\n",
      "layers:99, mean:0.23195801675319672\n",
      "tensor([[0.7324, 0.0400, 0.0581,  ..., 0.5915, 0.9844, 0.1552],\n",
      "        [0.4923, 0.0144, 0.0171,  ..., 0.4294, 0.6278, 0.1478],\n",
      "        [0.6296, 0.0590, 0.0000,  ..., 0.6069, 0.8445, 0.2575],\n",
      "        ...,\n",
      "        [0.4670, 0.0459, 0.0287,  ..., 0.4001, 0.6003, 0.1102],\n",
      "        [0.4546, 0.0899, 0.0440,  ..., 0.4066, 0.6123, 0.0900],\n",
      "        [0.5812, 0.0882, 0.0507,  ..., 0.5331, 0.7533, 0.1382]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "不使用归一化\n",
    "'''\n",
    "\n",
    "neural_nums = 256\n",
    "layer_nums = 100\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums)\n",
    "net.initialize() # 不进行bn时 需要采用合适的初始化\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))  # normal: mean=0, std=1\n",
    "\n",
    "output = net(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:14:31.047880Z",
     "start_time": "2020-05-06T14:14:31.040869Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, neural_num, layers=100):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(neural_num, neural_num, bias=False) for i in range(layers)])\n",
    "        self.bns = nn.ModuleList([nn.BatchNorm1d(neural_num) for i in range(layers)])\n",
    "        self.neural_num = neural_num\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        for (i, linear), bn in zip(enumerate(self.linears), self.bns):\n",
    "            x = linear(x)\n",
    "            x = bn(x)  # bn层\n",
    "            x = torch.relu(x)\n",
    "\n",
    "            if torch.isnan(x.std()):\n",
    "                print(\"output is nan in {} layers\".format(i))\n",
    "                break\n",
    "\n",
    "            print(\"layers:{}, std:{}\".format(i, x.std().item()))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:15:01.078203Z",
     "start_time": "2020-05-06T14:15:00.305637Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers:0, std:0.5878563523292542\n",
      "layers:1, std:0.5806277990341187\n",
      "layers:2, std:0.5738962292671204\n",
      "layers:3, std:0.575210690498352\n",
      "layers:4, std:0.5790040493011475\n",
      "layers:5, std:0.5819441080093384\n",
      "layers:6, std:0.5825987458229065\n",
      "layers:7, std:0.582497775554657\n",
      "layers:8, std:0.5798506140708923\n",
      "layers:9, std:0.5772049427032471\n",
      "layers:10, std:0.579689085483551\n",
      "layers:11, std:0.5835692286491394\n",
      "layers:12, std:0.5786635875701904\n",
      "layers:13, std:0.5837998986244202\n",
      "layers:14, std:0.5886130332946777\n",
      "layers:15, std:0.5854383111000061\n",
      "layers:16, std:0.579085648059845\n",
      "layers:17, std:0.5850254893302917\n",
      "layers:18, std:0.5762629508972168\n",
      "layers:19, std:0.5866146683692932\n",
      "layers:20, std:0.5781558752059937\n",
      "layers:21, std:0.574286937713623\n",
      "layers:22, std:0.5843595862388611\n",
      "layers:23, std:0.571588397026062\n",
      "layers:24, std:0.5902033448219299\n",
      "layers:25, std:0.5834580659866333\n",
      "layers:26, std:0.575657069683075\n",
      "layers:27, std:0.5830262303352356\n",
      "layers:28, std:0.5779280662536621\n",
      "layers:29, std:0.5769360661506653\n",
      "layers:30, std:0.5767160058021545\n",
      "layers:31, std:0.5773587226867676\n",
      "layers:32, std:0.5833659768104553\n",
      "layers:33, std:0.5827240347862244\n",
      "layers:34, std:0.588001549243927\n",
      "layers:35, std:0.5783025026321411\n",
      "layers:36, std:0.5789352059364319\n",
      "layers:37, std:0.5823203921318054\n",
      "layers:38, std:0.582011342048645\n",
      "layers:39, std:0.5804988741874695\n",
      "layers:40, std:0.5865800976753235\n",
      "layers:41, std:0.5828033685684204\n",
      "layers:42, std:0.5820366144180298\n",
      "layers:43, std:0.580944299697876\n",
      "layers:44, std:0.5770723819732666\n",
      "layers:45, std:0.5886620283126831\n",
      "layers:46, std:0.5840455293655396\n",
      "layers:47, std:0.5801437497138977\n",
      "layers:48, std:0.5746460556983948\n",
      "layers:49, std:0.5758756399154663\n",
      "layers:50, std:0.5820702314376831\n",
      "layers:51, std:0.5853630900382996\n",
      "layers:52, std:0.5834813714027405\n",
      "layers:53, std:0.5785165429115295\n",
      "layers:54, std:0.5839263796806335\n",
      "layers:55, std:0.5819241404533386\n",
      "layers:56, std:0.5787292122840881\n",
      "layers:57, std:0.5810473561286926\n",
      "layers:58, std:0.5772876739501953\n",
      "layers:59, std:0.5790991187095642\n",
      "layers:60, std:0.5796506404876709\n",
      "layers:61, std:0.5839870572090149\n",
      "layers:62, std:0.5782769322395325\n",
      "layers:63, std:0.5690767168998718\n",
      "layers:64, std:0.5755441784858704\n",
      "layers:65, std:0.5807479023933411\n",
      "layers:66, std:0.5892514586448669\n",
      "layers:67, std:0.5804204344749451\n",
      "layers:68, std:0.5809116363525391\n",
      "layers:69, std:0.5820646286010742\n",
      "layers:70, std:0.579837441444397\n",
      "layers:71, std:0.578990638256073\n",
      "layers:72, std:0.5890200734138489\n",
      "layers:73, std:0.5836957097053528\n",
      "layers:74, std:0.5777581334114075\n",
      "layers:75, std:0.583897054195404\n",
      "layers:76, std:0.5837026834487915\n",
      "layers:77, std:0.581025242805481\n",
      "layers:78, std:0.5738819241523743\n",
      "layers:79, std:0.5786482095718384\n",
      "layers:80, std:0.5824704170227051\n",
      "layers:81, std:0.57596355676651\n",
      "layers:82, std:0.5747760534286499\n",
      "layers:83, std:0.5850422978401184\n",
      "layers:84, std:0.5732941031455994\n",
      "layers:85, std:0.5825141072273254\n",
      "layers:86, std:0.5786454677581787\n",
      "layers:87, std:0.5843400359153748\n",
      "layers:88, std:0.578265368938446\n",
      "layers:89, std:0.5793028473854065\n",
      "layers:90, std:0.5809772610664368\n",
      "layers:91, std:0.5881218314170837\n",
      "layers:92, std:0.5821980237960815\n",
      "layers:93, std:0.5867171883583069\n",
      "layers:94, std:0.5758522748947144\n",
      "layers:95, std:0.584801971912384\n",
      "layers:96, std:0.5793632864952087\n",
      "layers:97, std:0.5760703086853027\n",
      "layers:98, std:0.5795462727546692\n",
      "layers:99, std:0.5771759748458862\n",
      "tensor([[0.0000, 1.2732, 0.0000,  ..., 0.0000, 1.4206, 1.5071],\n",
      "        [0.0000, 1.5101, 1.5785,  ..., 0.0000, 0.0000, 0.6476],\n",
      "        [0.2692, 0.0000, 0.0000,  ..., 0.0000, 1.7460, 0.0000],\n",
      "        ...,\n",
      "        [1.9108, 0.0000, 1.4709,  ..., 0.0000, 1.5120, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.5180,  ..., 0.0626, 0.0000, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "添加bn层的结果\n",
    "'''\n",
    "neural_nums = 256\n",
    "layer_nums = 100\n",
    "batch_size = 16\n",
    "\n",
    "net = MLP(neural_nums, layer_nums) # 使用bn层  不使用初始化  而且更优越\n",
    "\n",
    "inputs = torch.randn((batch_size, neural_nums))  # normal: mean=0, std=1\n",
    "\n",
    "output = net(inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN层的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BN层的主要属性**\n",
    "\n",
    "    - running_mean\n",
    "        均值\n",
    "    \n",
    "    - running_var \n",
    "        方差\n",
    "    \n",
    "    - weight \n",
    "        gama        \n",
    "    \n",
    "    - bias\n",
    "        beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T07:42:26.550556Z",
     "start_time": "2019-12-29T07:42:26.512653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 16, 784])\n",
      "tensor([0.0501, 0.0496, 0.0500, 0.0502, 0.0499, 0.0498, 0.0500, 0.0501, 0.0499,\n",
      "        0.0500, 0.0500, 0.0500, 0.0502, 0.0498, 0.0500, 0.0500])\n",
      "tensor([0.9083, 0.9084, 0.9084, 0.9084, 0.9084, 0.9083, 0.9083, 0.9083, 0.9083,\n",
      "        0.9084, 0.9084, 0.9083, 0.9083, 0.9083, 0.9083, 0.9083])\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.BatchNorm层的属性\n",
    "\n",
    "x = torch.rand(100, 16, 28 * 28)\n",
    "\n",
    "layer = nn.BatchNorm1d(16)\n",
    "\n",
    "out = layer(x)\n",
    "print(out.shape)\n",
    "print(layer.running_mean)\n",
    "print(layer.running_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    对小批量(mini-batch)的2d或3d输入进行批标准化(Batch Normalization)操作，计算输入各个维度的均值和标准差。\n",
    "    \n",
    "    代替权值的初始化以及权重衰减\n",
    "\n",
    "- num_features： \n",
    "\n",
    "    来自期望输入的特征数\n",
    "\n",
    "- eps： \n",
    "\n",
    "    为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。\n",
    "\n",
    "- momentum： \n",
    "\n",
    "    动态均值和动态方差所使用的动量。默认为0.1。\n",
    "    \n",
    "    即通过指数加权平均来估计样本均值与方差\n",
    "    \n",
    "        running_mean=(1-momentum)*pre_running_mean+momentum*mean_t\n",
    "        \n",
    "        running_var=(1-momentum)*pre_running_var+momentum*var_t\n",
    "\n",
    "- affine： \n",
    "\n",
    "    一个布尔值，当设为true，给该层添加可学习的仿射变换参数。\n",
    "\n",
    "- track_running_stats\n",
    "    \n",
    "    给定是训练状态还是测试状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BN1d的计算原理**\n",
    "\n",
    "![](./bn1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T14:47:35.374052Z",
     "start_time": "2020-05-06T14:47:35.242436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data:\n",
      "tensor([[[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]],\n",
      "\n",
      "        [[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]],\n",
      "\n",
      "        [[1.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.]]]) shape is torch.Size([3, 5, 1])\n",
      "\n",
      "iteration:0, running mean: tensor([0.3000, 0.6000, 0.9000, 1.2000, 1.5000]) \n",
      "iteration:0, running var:tensor([0.7000, 0.7000, 0.7000, 0.7000, 0.7000]) \n",
      "iteration:0, 第二个特征的running mean: 0.6 \n",
      "iteration:0, 第二个特征的running var:0.7\n",
      "\n",
      "iteration:1, running mean: tensor([0.5100, 1.0200, 1.5300, 2.0400, 2.5500]) \n",
      "iteration:1, running var:tensor([0.4900, 0.4900, 0.4900, 0.4900, 0.4900]) \n",
      "iteration:1, 第二个特征的running mean: 1.02 \n",
      "iteration:1, 第二个特征的running var:0.48999999999999994\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.BatchNorm1d\n",
    "\n",
    "'''\n",
    "针对全连接层使用\n",
    "'''\n",
    "batch_size = 3\n",
    "num_features = 5 # 5个特征\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (1)\n",
    "\n",
    "feature_map = torch.ones(features_shape)                                                    # 1D\n",
    "feature_maps = torch.stack([feature_map*(i+1) for i in range(num_features)], dim=0)         # 2D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)             # 3D\n",
    "print(\"input data:\\n{} shape is {}\".format(feature_maps_bs, feature_maps_bs.shape))\n",
    "\n",
    "bn = nn.BatchNorm1d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "running_mean, running_var = 0, 1\n",
    "\n",
    "for i in range(2):\n",
    "    '''\n",
    "    注意bn将计算特征维度上的均值与方差\n",
    "    '''\n",
    "    outputs = bn(feature_maps_bs) # 输入3*5*1  5*1输出形状\n",
    "\n",
    "    print(\"\\niteration:{}, running mean: {} \".format(i, bn.running_mean))\n",
    "    print(\"iteration:{}, running var:{} \".format(i, bn.running_var))\n",
    "\n",
    "    mean_t, var_t = 2, 0\n",
    "    \n",
    "    # 手动计算\n",
    "    running_mean = (1 - momentum) * running_mean + momentum * mean_t\n",
    "    running_var = (1 - momentum) * running_var + momentum * var_t\n",
    "\n",
    "    print(\"iteration:{}, 第二个特征的running mean: {} \".format(i, running_mean))\n",
    "    print(\"iteration:{}, 第二个特征的running var:{}\".format(i, running_var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)\n",
    "\n",
    "- num_features： \n",
    "\n",
    "    来自期望输入的特征数，该期望输入的大小为'batch_size x num_features [x width]'\n",
    "\n",
    "- eps： \n",
    "\n",
    "    为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。\n",
    "\n",
    "- momentum： \n",
    "\n",
    "    动态均值和动态方差所使用的动量。默认为0.1。\n",
    "\n",
    "- affine： \n",
    "\n",
    "    一个布尔值，当设为true，给该层添加可学习的仿射变换参数。\n",
    "\n",
    "- Shape： \n",
    "\n",
    "     输入：（N, C）或者(N, C, L) - 输出：（N, C）或者（N，C，L）（输入输出相同）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**bn2d原理**\n",
    "\n",
    "![](./bn2d.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T15:09:50.188980Z",
     "start_time": "2020-05-06T15:09:50.157063Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data:\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]],\n",
      "\n",
      "\n",
      "        [[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]]]]) shape is torch.Size([3, 3, 2, 2])\n",
      "\n",
      "iteration:0, running mean: tensor([0.3000, 0.6000, 0.9000]) \n",
      "\n",
      "iter:0, running_mean.shape: torch.Size([3])\n",
      "iter:0, running_var.shape: torch.Size([3])\n",
      "iter:0, weight.shape: torch.Size([3])\n",
      "iter:0, bias.shape: torch.Size([3])\n",
      "\n",
      "iteration:1, running mean: tensor([0.5100, 1.0200, 1.5300]) \n",
      "\n",
      "iter:1, running_mean.shape: torch.Size([3])\n",
      "iter:1, running_var.shape: torch.Size([3])\n",
      "iter:1, weight.shape: torch.Size([3])\n",
      "iter:1, bias.shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.BatchNorm2d\n",
    "batch_size = 3\n",
    "num_features = 3\n",
    "momentum = 0.3\n",
    "    \n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)                                                    # 2D\n",
    "feature_maps = torch.stack([feature_map*(i+1) for i in range(num_features)], dim=0)         # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)             # 4D\n",
    "\n",
    "print(\"input data:\\n{} shape is {}\".format(feature_maps_bs, feature_maps_bs.shape))\n",
    "\n",
    "bn = nn.BatchNorm2d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "running_mean, running_var = 0, 1\n",
    "\n",
    "for i in range(2):\n",
    "    outputs = bn(feature_maps_bs)\n",
    "    \n",
    "    print(\"\\niteration:{}, running mean: {} \".format(i, bn.running_mean))\n",
    "    \n",
    "    print(\"\\niter:{}, running_mean.shape: {}\".format(i, bn.running_mean.shape))\n",
    "    print(\"iter:{}, running_var.shape: {}\".format(i, bn.running_var.shape))\n",
    "\n",
    "    print(\"iter:{}, weight.shape: {}\".format(i, bn.weight.shape))\n",
    "    print(\"iter:{}, bias.shape: {}\".format(i, bn.bias.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T07:56:39.569715Z",
     "start_time": "2019-12-29T07:56:39.465023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_backend': <torch.nn.backends.thnn.THNNFunctionBackend at 0x2a45377a160>,\n",
       " '_parameters': OrderedDict([('weight', Parameter containing:\n",
       "               tensor([0.3507, 0.0740, 0.1083, 0.2431, 0.4291, 0.2763, 0.9373, 0.5150, 0.5816,\n",
       "                       0.0219, 0.4399, 0.6164, 0.8034, 0.0686, 0.5728, 0.1637],\n",
       "                      requires_grad=True)), ('bias', Parameter containing:\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      requires_grad=True))]),\n",
       " '_buffers': OrderedDict([('running_mean',\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "              ('running_var',\n",
       "               tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "              ('num_batches_tracked', tensor(0))]),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'training': True,\n",
       " 'num_features': 16,\n",
       " 'eps': 1e-05,\n",
       " 'momentum': 0.1,\n",
       " 'affine': True,\n",
       " 'track_running_stats': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True)\n",
    "\n",
    "- num_features： \n",
    "\n",
    "    来自期望输入的特征数，该期望输入的大小为'batch_size x num_features depth x height x width'\n",
    "\n",
    "- eps： \n",
    "\n",
    "    为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。\n",
    "\n",
    "- momentum： \n",
    "\n",
    "    动态均值和动态方差所使用的动量。默认为0.1。\n",
    "\n",
    "- affine： \n",
    "\n",
    "    一个布尔值，当设为true，给该层添加可学习的仿射变换参数。\n",
    "\n",
    "- Shape： \n",
    "    \n",
    "    输入：（N, C，D, H, W)\n",
    "    \n",
    "    输出：（N, C, D, H, W）（输入输出相同）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================== nn.BatchNorm3d\n",
    "\n",
    "batch_size = 3\n",
    "num_features = 4\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (2, 2, 3)\n",
    "\n",
    "feature = torch.ones(features_shape)                                                # 3D\n",
    "feature_map = torch.stack([feature * (i + 1) for i in range(num_features)], dim=0)  # 4D\n",
    "feature_maps = torch.stack([feature_map for i in range(batch_size)], dim=0)         # 5D\n",
    "\n",
    "print(\"input data:\\n{} shape is {}\".format(feature_maps, feature_maps.shape))\n",
    "\n",
    "bn = nn.BatchNorm3d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "running_mean, running_var = 0, 1\n",
    "\n",
    "for i in range(2):\n",
    "    outputs = bn(feature_maps)\n",
    "\n",
    "    print(\"\\niter:{}, running_mean.shape: {}\".format(i, bn.running_mean.shape))\n",
    "    print(\"iter:{}, running_var.shape: {}\".format(i, bn.running_var.shape))\n",
    "\n",
    "    print(\"iter:{}, weight.shape: {}\".format(i, bn.weight.shape))\n",
    "    print(\"iter:{}, bias.shape: {}\".format(i, bn.bias.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他类型归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Layer Norm**\n",
    "\n",
    "![](./ln.jpg)\n",
    "\n",
    "    - 解决BN无法适用于特征层间不同大小的RNN等网络\n",
    "\n",
    "    - 计算特征维度上的均值与方差 \n",
    "    \n",
    "    - 没有running_mean 和 running_var\n",
    "    \n",
    "    - gama 与 beta 是逐元素的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nn.LayerNorm(normalized_shape, eps, elementwise_affine)\n",
    "    \n",
    "- normalized_shape\n",
    "    \n",
    "    计算层的形状，按该形状为基数计算均值方差\n",
    "\n",
    "- eps\n",
    "\n",
    "    分母修正\n",
    "    \n",
    "- elementwise_affine\n",
    "\n",
    "    是否需要gamma beta进行变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:10:05.491579Z",
     "start_time": "2020-05-06T16:10:05.472631Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Normalization\n",
      "torch.Size([3, 2, 2])\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[2., 2.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [3., 3.]]])\n",
      "tensor([[[-1.2247, -1.2247],\n",
      "         [-1.2247, -1.2247]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.2247,  1.2247],\n",
      "         [ 1.2247,  1.2247]]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.layer norm\n",
    "batch_size = 8\n",
    "num_features = 3\n",
    "\n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)  # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "# feature_maps_bs shape is [8, 6, 3, 4],  B * C * H * W\n",
    "ln = nn.LayerNorm(feature_maps_bs.size()[1:], elementwise_affine=True)\n",
    "\n",
    "output = ln(feature_maps_bs)\n",
    "\n",
    "print(\"Layer Normalization\")\n",
    "print(ln.weight.shape) # weight就是gama\n",
    "print(feature_maps_bs[0, ...])\n",
    "print(output[0, ...]) # 计算每个样本的12个元素均值与方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:25:06.405899Z",
     "start_time": "2020-05-06T16:25:06.366973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 + 2 + 3) * 4 / (3 * 2 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:40:49.213777Z",
     "start_time": "2020-05-06T16:40:49.194830Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Normalization\n",
      "None\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[2., 2.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [3., 3.]]])\n",
      "tensor([[[-1.2247, -1.2247],\n",
      "         [-1.2247, -1.2247]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 1.2247,  1.2247],\n",
      "         [ 1.2247,  1.2247]]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.layer norm  elementwise_affine=False\n",
    "batch_size = 8\n",
    "num_features = 3\n",
    "\n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)  # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "# feature_maps_bs shape is [8, 6, 3, 4],  B * C * H * W\n",
    "ln = nn.LayerNorm(feature_maps_bs.size()[1:], elementwise_affine=False) # 不需要transform\n",
    "\n",
    "output = ln(feature_maps_bs)\n",
    "\n",
    "print(\"Layer Normalization\")\n",
    "print(ln.weight) # 没有weight\n",
    "print(feature_maps_bs[0, ...])\n",
    "print(output[0, ...]) # 计算每个样本的12个元素均值与方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:45:47.437307Z",
     "start_time": "2020-05-06T16:45:47.414394Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Normalization\n",
      "torch.Size([3, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.],\n",
      "         [2., 2., 2., 2.]],\n",
      "\n",
      "        [[3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.],\n",
      "         [3., 3., 3., 3.]],\n",
      "\n",
      "        [[4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4.],\n",
      "         [4., 4., 4., 4.]],\n",
      "\n",
      "        [[5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.],\n",
      "         [5., 5., 5., 5.]],\n",
      "\n",
      "        [[6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.],\n",
      "         [6., 6., 6., 6.]]])\n",
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.layer norm  自定义计算层\n",
    "batch_size = 8\n",
    "num_features = 6\n",
    "\n",
    "features_shape = (3, 4)\n",
    "\n",
    "feature_map = torch.ones(features_shape)  # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "# feature_maps_bs shape is [8, 6, 3, 4],  B * C * H * W\n",
    "ln = nn.LayerNorm([3, 4])\n",
    "\n",
    "output = ln(feature_maps_bs)\n",
    "\n",
    "print(\"Layer Normalization\")\n",
    "print(ln.weight.shape)\n",
    "print(feature_maps_bs[0, ...])\n",
    "print(output[0, ...]) # 计算一个（3，4）里的元素均值进行标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Instance Norm**\n",
    "\n",
    "\n",
    "![](./In.jpg)\n",
    "\n",
    "\n",
    "**特点**\n",
    "\n",
    "    - BN无法再生成模型中使用，不适用于风格差异较大的图像\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nn.InstanceNorm2d(num_features,eps,momentum,affine,track_running_stats)\n",
    "\n",
    "- num_features\n",
    "\n",
    "    特征数量\n",
    "\n",
    "- eps\n",
    "\n",
    "    分母修正项\n",
    "    \n",
    "- momentum\n",
    "    \n",
    "    动量\n",
    "\n",
    "- affine\n",
    "\n",
    "    是否需要仿射变换\n",
    "    \n",
    "- track_running_stats\n",
    "\n",
    "    训练还是测试模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T12:37:20.441306Z",
     "start_time": "2020-05-07T12:37:20.423354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance Normalization\n",
      "input data:\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[2., 2.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [3., 3.]]]) shape is torch.Size([3, 3, 2, 2])\n",
      "tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.instance norm 2d\n",
    "batch_size = 3\n",
    "num_features = 3\n",
    "momentum = 0.3\n",
    "\n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)    # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "print(\"Instance Normalization\")\n",
    "print(\"input data:\\n{} shape is {}\".format(feature_maps_bs[0], feature_maps_bs.shape))\n",
    "\n",
    "instance_n = nn.InstanceNorm2d(num_features=num_features, momentum=momentum)\n",
    "\n",
    "outputs = instance_n(feature_maps_bs)\n",
    "\n",
    "print(outputs[0])\n",
    "# print(\"\\niter:{}, running_mean.shape: {}\".format(i, bn.running_mean.shape))\n",
    "# print(\"iter:{}, running_var.shape: {}\".format(i, bn.running_var.shape))\n",
    "# print(\"iter:{}, weight.shape: {}\".format(i, bn.weight.shape))\n",
    "# print(\"iter:{}, bias.shape: {}\".format(i, bn.bias.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Group_Norm**\n",
    "\n",
    "![](./gn.jpg)\n",
    "\n",
    "特点:\n",
    "\n",
    "    - batch过小导致的均值方差估计不准\n",
    "    \n",
    "    - 应用于大模型小batch的情形中\n",
    "    \n",
    "    - 对特征通道进行分组，计入均值方差计算\n",
    "    \n",
    "    - 无running_mean  running_var\n",
    "    \n",
    "    - gamma  beta 逐通道"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    nn.GroupNorm(num_groups,num_channels,eps,affine)\n",
    "\n",
    "- num_groups\n",
    "\n",
    "    分组数\n",
    "\n",
    "- num_channels\n",
    "\n",
    "    特征数\n",
    "    \n",
    "- eps\n",
    "\n",
    "    分母修正项\n",
    "    \n",
    "- affine\n",
    "\n",
    "    是否变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T13:23:50.913543Z",
     "start_time": "2020-05-07T13:23:50.892621Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group Normalization\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]],\n",
      "\n",
      "         [[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[3., 3.],\n",
      "          [3., 3.]],\n",
      "\n",
      "         [[4., 4.],\n",
      "          [4., 4.]]],\n",
      "\n",
      "\n",
      "        [[[2., 2.],\n",
      "          [2., 2.]],\n",
      "\n",
      "         [[4., 4.],\n",
      "          [4., 4.]],\n",
      "\n",
      "         [[6., 6.],\n",
      "          [6., 6.]],\n",
      "\n",
      "         [[8., 8.],\n",
      "          [8., 8.]]]])\n",
      "torch.Size([4])\n",
      "tensor([[[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000]],\n",
      "\n",
      "        [[-1.0000, -1.0000],\n",
      "         [-1.0000, -1.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000]]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# ======================================== nn.grop norm\n",
    "\n",
    "batch_size = 2\n",
    "num_features = 4\n",
    "num_groups = 2   # 3 Expected number of channels in input to be divisible by num_groups\n",
    "\n",
    "features_shape = (2, 2)\n",
    "\n",
    "feature_map = torch.ones(features_shape)    # 2D\n",
    "feature_maps = torch.stack([feature_map * (i + 1) for i in range(num_features)], dim=0)  # 3D\n",
    "feature_maps_bs = torch.stack([feature_maps * (i + 1) for i in range(batch_size)], dim=0)  # 4D\n",
    "\n",
    "gn = nn.GroupNorm(num_groups, num_features)\n",
    "outputs = gn(feature_maps_bs)\n",
    "\n",
    "print(\"Group Normalization\")\n",
    "print(feature_maps_bs)\n",
    "print(gn.weight.shape)\n",
    "print(outputs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
