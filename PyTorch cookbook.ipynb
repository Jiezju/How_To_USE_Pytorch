{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:21:17.371940Z",
     "start_time": "2020-05-27T08:21:09.413374Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要包\n",
    "import collections\n",
    "import os\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 基础配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查PyTorch版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:22:01.948851Z",
     "start_time": "2020-05-27T08:22:01.936911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:22:11.135470Z",
     "start_time": "2020-05-27T08:22:11.130484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:22:20.159647Z",
     "start_time": "2020-05-27T08:22:19.804375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7501"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:22:35.892287Z",
     "start_time": "2020-05-27T08:22:35.571053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更新PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:23:17.265435Z",
     "start_time": "2020-05-27T08:23:17.261447Z"
    }
   },
   "outputs": [],
   "source": [
    "# conda update pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置随机种子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:23:51.557633Z",
     "start_time": "2020-05-27T08:23:51.553635Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定程序运行在特定GPU卡上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:24:41.031697Z",
     "start_time": "2020-05-27T08:24:41.028704Z"
    }
   },
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=0,1 python train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:24:54.418343Z",
     "start_time": "2020-05-27T08:24:54.415352Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在代码中指定： os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断是否有CUDA支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:25:22.653408Z",
     "start_time": "2020-05-27T08:25:22.649376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置为cuDNN benchmark模式 \n",
    "\n",
    "- Benchmark模式会提升计算速度，但是由于计算中有随机性，每次网络前馈结果略有差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:26:21.785180Z",
     "start_time": "2020-05-27T08:26:21.781192Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清除GPU存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:26:42.797922Z",
     "start_time": "2020-05-27T08:26:42.793932Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T08:27:10.155176Z",
     "start_time": "2020-05-27T08:27:10.152197Z"
    }
   },
   "outputs": [],
   "source": [
    "# nvidia-smi --gpu-reset -i [gpu_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 张量处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.type()   # Data type\n",
    "tensor.size()   # Shape of the tensor. It is a subclass of Python tuple\n",
    "tensor.dim()    # Number of dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据类型转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default tensor type. Float in PyTorch is much faster than double.\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "# Type convertions.\n",
    "tensor = tensor.cuda()\n",
    "tensor = tensor.cpu()\n",
    "tensor = tensor.float()\n",
    "tensor = tensor.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与np.ndarray转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor -> np.ndarray.\n",
    "ndarray = tensor.cpu().numpy()\n",
    "\n",
    "# np.ndarray -> torch.Tensor.\n",
    "tensor = torch.from_numpy(ndarray).float()\n",
    "tensor = torch.from_numpy(ndarray.copy()).float()  # If ndarray has negative stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.Tensor与PIL.Image转换\n",
    "\n",
    "- PyTorch中的张量默认采用N×D×H×W的顺序，并且数据范围在[0, 1]，需要进行转置和规范化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.Tensor -> PIL.Image.\n",
    "image = PIL.Image.fromarray(torch.clamp(tensor * 255, min=0, max=255).byte().permute(1, 2, 0).cpu().numpy())\n",
    "image = torchvision.transforms.functional.to_pil_image(tensor)  # Equivalently way\n",
    "\n",
    "# PIL.Image -> torch.Tensor.\n",
    "tensor = torch.from_numpy(np.asarray(PIL.Image.open(path))).permute(2, 0, 1).float() / 255\n",
    "tensor = torchvision.transforms.functional.to_tensor(PIL.Image.open(path))  # Equivalently way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从只包含一个元素的张量中提取值\n",
    "\n",
    "- 这在训练时统计loss的变化过程中特别有用。否则这将累积计算图，使GPU存储占用量越来越大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = tensor.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量形变\n",
    "\n",
    "- 张量形变常常需要用于将卷积层特征输入全连接层的情形。相比torch.view，torch.reshape可以自动处理输入张量不连续的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.reshape(tensor, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打乱顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tensor[torch.randperm(tensor.size(0))]  # Shuffle the first dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 水平翻转\n",
    "- PyTorch不支持tensor[::-1]这样的负步长操作，水平翻转可以用张量索引实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tensor has shape N*D*H*W.\n",
    "tensor = tensor[:, :, :, torch.arange(tensor.size(3) - 1, -1, -1).long()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复制张量\n",
    "\n",
    "- 有三种复制的方式，对应不同的需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operation                 |  New/Shared memory | Still in computation graph |\n",
    "tensor.clone()            # |        New         |          Yes               |\n",
    "tensor.detach()           # |      Shared        |          No                |  截断梯度\n",
    "tensor.detach.clone()()   # |        New         |          No                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拼接张量\n",
    "\n",
    "- 注意torch.cat和torch.stack的区别在于torch.cat沿着给定的维度拼接，而torch.stack会新增一维。例如当参数是3个10×5的张量，torch.cat的结果是30×5的张量，而torch.stack的结果是3×10×5的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.cat(list_of_tensors, dim=0)\n",
    "tensor = torch.stack(list_of_tensors, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将整数标记转换成独热（one-hot）编码\n",
    "\n",
    "- PyTorch中的标记默认从0开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = tensor.size(0)\n",
    "one_hot = torch.zeros(N, num_classes).long()\n",
    "one_hot.scatter_(dim=1, index=torch.unsqueeze(tensor, dim=1), src=torch.ones(N, num_classes).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.one_hot(tensor,num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到非零/零元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nonzero(tensor)               # Index of non-zero elements\n",
    "torch.nonzero(tensor == 0)          # Index of zero elements\n",
    "torch.nonzero(tensor).size(0)       # Number of non-zero elements\n",
    "torch.nonzero(tensor == 0).size(0)  # Number of zero elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断两个张量相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(tensor1, tensor2)  # float tensor\n",
    "torch.equal(tensor1, tensor2)     # int tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand tensor of shape 64*512 to shape 64*512*7*7.\n",
    "torch.reshape(tensor, (64, 512, 1, 1)).expand(64, 512, 7, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication: (m*n) * (n*p) -> (m*p).\n",
    "result = torch.mm(tensor1, tensor2)\n",
    "\n",
    "# Batch matrix multiplication: (b*m*n) * (b*n*p) -> (b*m*p).\n",
    "result = torch.bmm(tensor1, tensor2)\n",
    "\n",
    "# Element-wise multiplication.\n",
    "result = tensor1 * tensor2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算两组数据之间的两两欧式距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 is of shape m*d, X2 is of shape n*d.\n",
    "dist = torch.sqrt(torch.sum((X1[:,None,:] - X2) ** 2, dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True)\n",
    "conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAP（Global average pooling）层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = torch.nn.AdaptiveAvgPool2d(output_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 双线性汇合（bilinear pooling）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.reshape(N, D, H * W)                        # Assume X has shape N*D*H*W\n",
    "X = torch.bmm(X, torch.transpose(X, 1, 2)) / (H * W)  # Bilinear pooling\n",
    "assert X.size() == (N, D, D)\n",
    "X = torch.reshape(X, (N, D * D))\n",
    "X = torch.sign(X) * torch.sqrt(torch.abs(X) + 1e-5)   # Signed-sqrt normalization\n",
    "X = torch.nn.functional.normalize(X)                  # L2 normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多卡同步BN（Batch normalization）\n",
    "\n",
    "- 当使用torch.nn.DataParallel将代码运行在多张GPU卡上时，PyTorch的BN层默认操作是各卡上数据独立地计算均值和标准差，同步BN使用所有卡上的数据一起计算BN层的均值和标准差，缓解了当批量大小（batch size）比较小时对均值和标准差估计不准的情况，是在目标检测等任务中一个有效的提升性能的技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sync_bn = torch.nn.SyncBatchNorm(num_features, eps=1e-05, momentum=0.1, affine=True,track_running_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T13:27:12.351270Z",
     "start_time": "2020-05-27T13:27:12.344292Z"
    }
   },
   "outputs": [],
   "source": [
    "# 将已有网络的所有BN层改为同步BN层\n",
    "def convertBNtoSyncBN(module, process_group=None):\n",
    "    '''Recursively replace all BN layers to SyncBN layer.\n",
    "\n",
    "    Args:\n",
    "        module[torch.nn.Module]. Network\n",
    "    '''\n",
    "    if isinstance(module, torch.nn.modules.batchnorm._BatchNorm):\n",
    "        sync_bn = torch.nn.SyncBatchNorm(module.num_features, module.eps,\n",
    "                                         module.momentum, module.affine,\n",
    "                                         module.track_running_stats,\n",
    "                                         process_group)\n",
    "        sync_bn.running_mean = module.running_mean\n",
    "        sync_bn.running_var = module.running_var\n",
    "        if module.affine:\n",
    "            sync_bn.weight = module.weight.clone().detach()\n",
    "            sync_bn.bias = module.bias.clone().detach()\n",
    "        return sync_bn\n",
    "    else:\n",
    "        for name, child_module in module.named_children():\n",
    "            setattr(module, name=convert_syncbn_model(child_module, process_group=process_group))\n",
    "        return module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类似BN滑动平均\n",
    "\n",
    "- 如果要实现类似BN滑动平均的操作，在forward函数中要使用原地（inplace）操作给滑动平均赋值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BN(torch.nn.Module)\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "\n",
    "    def forward(self, X):\n",
    "        ...\n",
    "        self.running_mean += momentum * (current - self.running_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算模型整体参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_parameters = sum(torch.numel(parameter) for parameter in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类似Keras的model.summary()输出模型信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "print(summary(model, (1, 32, 32), device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型权值初始化\n",
    "\n",
    "- 注意model.modules()和model.children()的区别：model.modules()会迭代地遍历模型的所有子层，而model.children()只会遍历模型下的一层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common practise for initialization.\n",
    "for layer in model.modules():\n",
    "    if isinstance(layer, torch.nn.Conv2d):\n",
    "        torch.nn.init.kaiming_normal_(layer.weight, mode='fan_out',\n",
    "                                      nonlinearity='relu')\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.BatchNorm2d):\n",
    "        torch.nn.init.constant_(layer.weight, val=1.0)\n",
    "        torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "    elif isinstance(layer, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(layer.weight)\n",
    "        if layer.bias is not None:\n",
    "            torch.nn.init.constant_(layer.bias, val=0.0)\n",
    "\n",
    "# Initialization with given tensor.\n",
    "layer.weight = torch.nn.Parameter(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部分层使用预训练模型\n",
    "\n",
    "- 注意如果保存的模型是torch.nn.DataParallel，则当前的模型也需要是torch.nn.DataParallel。torch.nn.DataParallel(model).module == model。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将在GPU保存的模型加载到CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model,pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据准备、特征提取与微调"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像分块打散（image shuffle）/区域混淆机制（region confusion mechanism，RCM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is torch.Tensor of size N*D*H*W.\n",
    "# Shuffle rows\n",
    "Q = (torch.unsqueeze(torch.arange(num_blocks), dim=1) * torch.ones(1, num_blocks).long()\n",
    "     + torch.randint(low=-neighbour, high=neighbour, size=(num_blocks, num_blocks)))\n",
    "Q = torch.argsort(Q, dim=0)\n",
    "assert Q.size() == (num_blocks, num_blocks)\n",
    "\n",
    "X = [torch.chunk(row, chunks=num_blocks, dim=2)\n",
    "     for row in torch.chunk(X, chunks=num_blocks, dim=1)]\n",
    "X = [[X[Q[i, j].item()][j] for j in range(num_blocks)]\n",
    "     for i in range(num_blocks)]\n",
    "\n",
    "# Shulle columns.\n",
    "Q = (torch.ones(num_blocks, 1).long() * torch.unsqueeze(torch.arange(num_blocks), dim=0)\n",
    "     + torch.randint(low=-neighbour, high=neighbour, size=(num_blocks, num_blocks)))\n",
    "Q = torch.argsort(Q, dim=1)\n",
    "assert Q.size() == (num_blocks, num_blocks)\n",
    "X = [[X[i][Q[i, j].item()] for j in range(num_blocks)]\n",
    "     for i in range(num_blocks)]\n",
    "\n",
    "Y = torch.cat([torch.cat(row, dim=2) for row in X], dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到视频数据基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "video = cv2.VideoCapture(mp4_path)\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSN每段（segment）采样一帧视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = self._num_segments\n",
    "if is_train:\n",
    "    if num_frames > K:\n",
    "        # Random index for each segment.\n",
    "        frame_indices = torch.randint(\n",
    "            high=num_frames // K, size=(K,), dtype=torch.long)\n",
    "        frame_indices += num_frames // K * torch.arange(K)\n",
    "    else:\n",
    "        frame_indices = torch.randint(\n",
    "            high=num_frames, size=(K - num_frames,), dtype=torch.long)\n",
    "        frame_indices = torch.sort(torch.cat((\n",
    "            torch.arange(num_frames), frame_indices)))[0]\n",
    "else:\n",
    "    if num_frames > K:\n",
    "        # Middle index for each segment.\n",
    "        frame_indices = num_frames / K // 2\n",
    "        frame_indices += num_frames // K * torch.arange(K)\n",
    "    else:\n",
    "        frame_indices = torch.sort(torch.cat((\n",
    "            torch.arange(num_frames), torch.arange(K - num_frames))))[0]\n",
    "assert frame_indices.size() == (K,)\n",
    "return [frame_indices[i] for i in range(K)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取ImageNet预训练模型某层的卷积特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG-16 relu5-3 feature.\n",
    "model = torchvision.models.vgg16(pretrained=True).features[:-1]\n",
    "# VGG-16 pool5 feature.\n",
    "model = torchvision.models.vgg16(pretrained=True).features\n",
    "# VGG-16 fc7 feature.\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model.classifier = torch.nn.Sequential(*list(model.classifier.children())[:-3])\n",
    "# ResNet GAP feature.\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(collections.OrderedDict(\n",
    "    list(model.named_children())[:-1]))\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    conv_representation = model(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取ImageNet预训练模型多层的卷积特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(torch.nn.Module):\n",
    "    \"\"\"Helper class to extract several convolution features from the given\n",
    "    pre-trained model.\n",
    "\n",
    "    Attributes:\n",
    "        _model, torch.nn.Module.\n",
    "        _layers_to_extract, list<str> or set<str>\n",
    "\n",
    "    Example:\n",
    "        >>> model = torchvision.models.resnet152(pretrained=True)\n",
    "        >>> model = torch.nn.Sequential(collections.OrderedDict(\n",
    "                list(model.named_children())[:-1]))\n",
    "        >>> conv_representation = FeatureExtractor(\n",
    "                pretrained_model=model,\n",
    "                layers_to_extract={'layer1', 'layer2', 'layer3', 'layer4'})(image)\n",
    "    \"\"\"\n",
    "    def __init__(self, pretrained_model, layers_to_extract):\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self._model = pretrained_model\n",
    "        self._model.eval()\n",
    "        self._layers_to_extract = set(layers_to_extract)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            conv_representation = []\n",
    "            for name, layer in self._model.named_children():\n",
    "                x = layer(x)\n",
    "                if name in self._layers_to_extract:\n",
    "                    conv_representation.append(x)\n",
    "            return conv_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 微调全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(512, 100)  # Replace the last fc layer\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以较大学习率微调全连接层，较小学习率微调卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "finetuned_parameters = list(map(id, model.fc.parameters()))\n",
    "conv_parameters = (p for p in model.parameters() if id(p) not in finetuned_parameters)\n",
    "parameters = [{'params': conv_parameters, 'lr': 1e-3},\n",
    "              {'params': model.fc.parameters()}]\n",
    "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用训练和验证数据预处理\n",
    "\n",
    "- 其中ToTensor操作会将PIL.Image或形状为H×W×D，数值范围为[0, 255]的np.ndarray转换为形状为D×H×W，数值范围为[0.0, 1.0]的torch.Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-27T13:54:15.274183Z",
     "start_time": "2020-05-27T13:54:15.262244Z"
    }
   },
   "outputs": [],
   "source": [
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(size=224,\n",
    "                                             scale=(0.08, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                     std=(0.229, 0.224, 0.225))])\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                                     std=(0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练基本代码框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in epoch(80):\n",
    "    for images, labels in tqdm.tqdm(train_loader, desc='Epoch %3d' % (t + 1)):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        scores = model(images)\n",
    "        loss = loss_function(scores, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标记平滑（label smoothing）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    N = labels.size(0)\n",
    "    # C is the number of classes.\n",
    "    smoothed_labels = torch.full(size=(N, C), fill_value=0.1 / (C - 1)).cuda()\n",
    "    smoothed_labels.scatter_(dim=1, index=torch.unsqueeze(labels, dim=1), value=0.9)\n",
    "\n",
    "    score = model(images)\n",
    "    log_prob = torch.nn.functional.log_softmax(score, dim=1)\n",
    "    loss = -torch.sum(log_prob * smoothed_labels) / N\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_distribution = torch.distributions.beta.Beta(alpha, alpha)\n",
    "for images, labels in train_loader:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "    # Mixup images.\n",
    "    lambda_ = beta_distribution.sample([]).item()\n",
    "    index = torch.randperm(images.size(0)).cuda()\n",
    "    mixed_images = lambda_ * images + (1 - lambda_) * images[index, :]\n",
    "\n",
    "    # Mixup loss.\n",
    "    scores = model(mixed_images)\n",
    "    loss = (lambda_ * loss_function(scores, labels)\n",
    "            + (1 - lambda_) * loss_function(scores, labels[index]))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_regularization = torch.nn.L1Loss(reduction='sum')\n",
    "loss = ...  # Standard cross-entropy loss\n",
    "for param in model.parameters():\n",
    "    loss += lambda_ * torch.sum(torch.abs(param))\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不对偏置项进行L2正则化/权值衰减（weight decay）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_list = (param for name, param in model.named_parameters() if name[-4:] == 'bias')\n",
    "others_list = (param for name, param in model.named_parameters() if name[-4:] != 'bias')\n",
    "parameters = [{'parameters': bias_list, 'weight_decay': 0},\n",
    "              {'parameters': others_list}]\n",
    "optimizer = torch.optim.SGD(parameters, lr=1e-2, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度裁剪（gradient clipping）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算Softmax输出的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model(images)\n",
    "prediction = torch.argmax(score, dim=1)\n",
    "num_correct = torch.sum(prediction == labels).item()\n",
    "accuruacy = num_correct / labels.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化模型前馈的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using Visdom.\n",
    "vis = visdom.Visdom(env='Learning curve', use_incoming_socket=False)\n",
    "assert self._visdom.check_connection()\n",
    "self._visdom.close()\n",
    "options = collections.namedtuple('Options', ['loss', 'acc', 'lr'])(\n",
    "    loss={'xlabel': 'Epoch', 'ylabel': 'Loss', 'showlegend': True},\n",
    "    acc={'xlabel': 'Epoch', 'ylabel': 'Accuracy', 'showlegend': True},\n",
    "    lr={'xlabel': 'Epoch', 'ylabel': 'Learning rate', 'showlegend': True})\n",
    "\n",
    "for t in epoch(80):\n",
    "    tran(...)\n",
    "    val(...)\n",
    "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([train_loss]),\n",
    "             name='train', win='Loss', update='append', opts=options.loss)\n",
    "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([val_loss]),\n",
    "             name='val', win='Loss', update='append', opts=options.loss)\n",
    "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([train_acc]),\n",
    "             name='train', win='Accuracy', update='append', opts=options.acc)\n",
    "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([val_acc]),\n",
    "             name='val', win='Accuracy', update='append', opts=options.acc)\n",
    "    vis.line(X=torch.Tensor([t + 1]), Y=torch.Tensor([lr]),\n",
    "             win='Learning rate', update='append', opts=options.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到当前学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is one global learning rate (which is the common case).\n",
    "lr = next(iter(optimizer.param_groups))['lr']\n",
    "\n",
    "# If there are multiple learning rates for different layers.\n",
    "all_lr = []\n",
    "for param_group in optimizer.param_groups:\n",
    "    all_lr.append(param_group['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习率衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce learning rate when validation accuarcy plateau.\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=5, verbose=True)\n",
    "for t in range(0, 80):\n",
    "    train(...); val(...)\n",
    "    scheduler.step(val_acc)\n",
    "\n",
    "# Cosine annealing learning rate.\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=80)\n",
    "# Reduce learning rate by 10 at given epochs.\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 70], gamma=0.1)\n",
    "for t in range(0, 80):\n",
    "    scheduler.step()\n",
    "    train(...); val(...)\n",
    "\n",
    "# Learning rate warmup by 10 epochs.\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda t: t / 10)\n",
    "for t in range(0, 10):\n",
    "    scheduler.step()\n",
    "    train(...); val(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存与加载断点\n",
    "\n",
    "- 注意为了能够恢复训练，我们需要同时保存模型和优化器的状态，以及当前的训练轮数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint.\n",
    "is_best = current_acc > best_acc\n",
    "best_acc = max(best_acc, current_acc)\n",
    "checkpoint = {\n",
    "    'best_acc': best_acc,\n",
    "    'epoch': t + 1,\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "}\n",
    "model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
    "torch.save(checkpoint, model_path)\n",
    "if is_best:\n",
    "    shutil.copy('checkpoint.pth.tar', model_path)\n",
    "\n",
    "# Load checkpoint.\n",
    "if resume:\n",
    "    model_path = os.path.join('model', 'checkpoint.pth.tar')\n",
    "    assert os.path.isfile(model_path)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print('Load checkpoint at epoch %d.' % start_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算准确率、查准率（precision）、查全率（recall）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['label'] and data['prediction'] are groundtruth label and prediction\n",
    "# for each image, respectively.\n",
    "accuracy = np.mean(data['label'] == data['prediction']) * 100\n",
    "\n",
    "# Compute recision and recall for each class.\n",
    "for c in range(len(num_classes)):\n",
    "    tp = np.dot((data['label'] == c).astype(int),\n",
    "                (data['prediction'] == c).astype(int))\n",
    "    tp_fp = np.sum(data['prediction'] == c)\n",
    "    tp_fn = np.sum(data['label'] == c)\n",
    "    precision = tp / tp_fp * 100\n",
    "    recall = tp / tp_fn * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 模型测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算每个类别的查准率（precision）、查全率（recall）、F1和总体指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "all_label = []\n",
    "all_prediction = []\n",
    "for images, labels in tqdm.tqdm(data_loader):\n",
    "    # Data.\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "    # Forward pass.\n",
    "    score = model(images)\n",
    "\n",
    "    # Save label and predictions.\n",
    "    prediction = torch.argmax(score, dim=1)\n",
    "    all_label.append(labels.cpu().numpy())\n",
    "    all_prediction.append(prediction.cpu().numpy())\n",
    "\n",
    "# Compute RP and confusion matrix.\n",
    "all_label = np.concatenate(all_label)\n",
    "assert len(all_label.shape) == 1\n",
    "all_prediction = np.concatenate(all_prediction)\n",
    "assert all_label.shape == all_prediction.shape\n",
    "micro_p, micro_r, micro_f1, _ = sklearn.metrics.precision_recall_fscore_support(\n",
    "    all_label, all_prediction, average='micro', labels=range(num_classes))\n",
    "class_p, class_r, class_f1, class_occurence = sklearn.metrics.precision_recall_fscore_support(\n",
    "    all_label, all_prediction, average=None, labels=range(num_classes))\n",
    "# Ci,j = #{y=i and hat_y=j}\n",
    "confusion_mat = sklearn.metrics.confusion_matrix(all_label,\n",
    "                                                 all_prediction,\n",
    "                                                 labels=range(num_classes))\n",
    "assert confusion_mat.shape == (num_classes, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将各类结果写入电子表格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Write results onto disk.\n",
    "with open(os.path.join(path, filename), 'wt', encoding='utf-8') as f:\n",
    "    f = csv.writer(f)\n",
    "    f.writerow([\n",
    "        'Class', 'Label', '# occurence', 'Precision', 'Recall', 'F1',\n",
    "        'Confused class 1', 'Confused class 2', 'Confused class 3',\n",
    "        'Confused 4', 'Confused class 5'\n",
    "    ])\n",
    "    for c in range(num_classes):\n",
    "        index = np.argsort(confusion_mat[:, c])[::-1][:5]\n",
    "        f.writerow([\n",
    "            label2class[c], c, class_occurence[c],\n",
    "            '%4.3f' % class_p[c],\n",
    "            '%4.3f' % class_r[c],\n",
    "            '%4.3f' % class_f1[c],\n",
    "            '%s:%d' % (label2class[index[0]], confusion_mat[index[0], c]),\n",
    "            '%s:%d' % (label2class[index[1]], confusion_mat[index[1], c]),\n",
    "            '%s:%d' % (label2class[index[2]], confusion_mat[index[2], c]),\n",
    "            '%s:%d' % (label2class[index[3]], confusion_mat[index[3], c]),\n",
    "            '%s:%d' % (label2class[index[4]], confusion_mat[index[4], c])\n",
    "        ])\n",
    "        f.writerow([\n",
    "            'All', '',\n",
    "            np.sum(class_occurence), micro_p, micro_r, micro_f1, '', '', '',\n",
    "            '', ''\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
