{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**hook函数**\n",
    "\n",
    "- 不改变函数主题  实现额外功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor.register_hook(grad)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    注册一个反向传播hook函数，实现对tensor的梯度进行处理\n",
    "    \n",
    "- grad\n",
    "\n",
    "    张量的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T12:29:01.611913Z",
     "start_time": "2020-05-05T12:28:51.336099Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient: tensor([5.]) tensor([2.]) None None None\n",
      "a_grad[0]:  tensor([2.])\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- 1 tensor hook 1 -----------------------------------\n",
    "'''\n",
    "基于hook函数保留释放的中间梯度\n",
    "'''\n",
    "\n",
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "a_grad = list()\n",
    "\n",
    "\n",
    "def grad_hook(grad):\n",
    "    a_grad.append(grad)\n",
    "\n",
    "# 加载hook函数，保存中间梯度\n",
    "handle = a.register_hook(grad_hook)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# 查看梯度\n",
    "print(\"gradient:\", w.grad, x.grad, a.grad, b.grad, y.grad)\n",
    "print(\"a_grad[0]: \", a_grad[0])\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T12:29:51.774815Z",
     "start_time": "2020-05-05T12:29:51.758859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.grad:  tensor([30.])\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- 2 tensor hook 2 -----------------------------------\n",
    "'''\n",
    "基于hook函数改变中间梯度\n",
    "'''\n",
    "\n",
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "a_grad = list()\n",
    "\n",
    "def grad_hook(grad):\n",
    "    grad *= 2\n",
    "    return grad*3 # 相当于grad*=6\n",
    "\n",
    "handle = w.register_hook(grad_hook)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# 查看梯度\n",
    "print(\"w.grad: \", w.grad)\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T12:53:05.789853Z",
     "start_time": "2020-05-05T12:53:05.784964Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 2, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Module.register_forward_hook(model,input,output)\n",
    "    \n",
    "- 功能\n",
    "\n",
    "    注册module的前向传播hook函数\n",
    "    \n",
    "- model\n",
    "\n",
    "    当前网络层\n",
    "    \n",
    "- input\n",
    "\n",
    "    当前网络层输入数据\n",
    "    \n",
    "- output\n",
    "\n",
    "    当前网络层输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T12:57:54.504610Z",
     "start_time": "2020-05-05T12:57:53.485454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: torch.Size([1, 2, 1, 1])\n",
      "output value: tensor([[[[ 9.]],\n",
      "\n",
      "         [[18.]]]], grad_fn=<MaxPool2DWithIndicesBackward>)\n",
      "\n",
      "feature maps shape: torch.Size([1, 2, 2, 2])\n",
      "output value: tensor([[[[ 9.,  9.],\n",
      "          [ 9.,  9.]],\n",
      "\n",
      "         [[18., 18.],\n",
      "          [18., 18.]]]], grad_fn=<ThnnConv2DBackward>)\n",
      "\n",
      "input shape: torch.Size([1, 1, 4, 4])\n",
      "input value: (tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]]),)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "记录中间的特征图结果\n",
    "'''\n",
    "\n",
    "    \n",
    "# 初始化网络\n",
    "net = Net()\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.data.detach().zero_()\n",
    "\n",
    "# 注册hook\n",
    "fmap_block = list()\n",
    "input_block = list()\n",
    "\n",
    "#  定义前向传播hook函数\n",
    "def forward_hook(module, data_input, data_output):\n",
    "    fmap_block.append(data_output)\n",
    "    input_block.append(data_input)\n",
    "    \n",
    "net.conv1.register_forward_hook(forward_hook) # 记录第一个卷积层的中间特征层输出结果\n",
    "\n",
    "\n",
    "# inference\n",
    "fake_img = torch.ones((1, 1, 4, 4))  # batch size * channel * H * W\n",
    "output = net(fake_img)\n",
    "\n",
    "loss_fnc = nn.L1Loss()\n",
    "target = torch.randn_like(output)\n",
    "loss = loss_fnc(target, output)\n",
    "loss.backward()\n",
    "\n",
    "# 打印整个网络输出结果\n",
    "print(\"output shape: {}\\noutput value: {}\\n\".format(output.shape, output))\n",
    "# 打印中间特征图\n",
    "print(\"feature maps shape: {}\\noutput value: {}\\n\".format(fmap_block[0].shape, fmap_block[0]))\n",
    "print(\"input shape: {}\\ninput value: {}\".format(input_block[0][0].shape, input_block[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Module.register_forward_pre_hook(model,input)\n",
    "    \n",
    "- 功能\n",
    "\n",
    "    注册module的前向传播**前**的hook函数\n",
    "    \n",
    "- model\n",
    "\n",
    "    当前网络层\n",
    "    \n",
    "- input\n",
    "\n",
    "    当前网络层输入数据\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T13:46:27.634564Z",
     "start_time": "2020-05-05T13:46:27.624618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward_pre_hook input:(tensor([[[[1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.],\n",
      "          [1., 1., 1., 1.]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# 初始化网络\n",
    "net = Net()\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.data.detach().zero_()\n",
    "\n",
    "# 注册hook 前向计算前实现\n",
    "def forward_pre_hook(module, data_input):\n",
    "    print(\"forward_pre_hook input:{}\".format(data_input))\n",
    "net.conv1.register_forward_pre_hook(forward_pre_hook)\n",
    "\n",
    "# inference\n",
    "fake_img = torch.ones((1, 1, 4, 4))  # batch size * channel * H * W\n",
    "output = net(fake_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Module.register_backward_hook(model,grad_input,grad_output)\n",
    "\n",
    "- 功能\n",
    "\n",
    "    注册module的反向传播hook函数\n",
    "    \n",
    "- model\n",
    "\n",
    "    当前网络层\n",
    "    \n",
    "- grad_input\n",
    "\n",
    "    当前网络层输入梯度数据\n",
    "    \n",
    "- grad_output\n",
    "\n",
    "    当前网络层输出梯度数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T13:53:30.369361Z",
     "start_time": "2020-05-05T13:53:30.241201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backward hook input:(None, tensor([[[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]],\n",
      "\n",
      "\n",
      "        [[[0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.5000]]]]), tensor([0.5000, 0.5000]))\n",
      "backward hook output:(tensor([[[[0.5000, 0.0000],\n",
      "          [0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5000, 0.0000],\n",
      "          [0.0000, 0.0000]]]]),)\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------- 3 Module.register_forward_hook and pre hook -----------------------------------\n",
    "def backward_hook(module, grad_input, grad_output):\n",
    "    print(\"backward hook input:{}\".format(grad_input))\n",
    "    print(\"backward hook output:{}\".format(grad_output))\n",
    "\n",
    "\n",
    "# 初始化网络\n",
    "net = Net()\n",
    "net.conv1.weight[0].detach().fill_(1)\n",
    "net.conv1.weight[1].detach().fill_(2)\n",
    "net.conv1.bias.data.detach().zero_()\n",
    "\n",
    "# 注册hook\n",
    "net.conv1.register_backward_hook(backward_hook)\n",
    "\n",
    "# inference\n",
    "fake_img = torch.ones((1, 1, 4, 4))  # batch size * channel * H * W\n",
    "output = net(fake_img)\n",
    "\n",
    "loss_fnc = nn.L1Loss()\n",
    "target = torch.randn_like(output)\n",
    "loss = loss_fnc(target, output)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于Hook函数实现卷积核和特征图的可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:20:07.887136Z",
     "start_time": "2020-05-05T14:19:53.621213Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "# ----------------------------------- feature map visualization -----------------------------------\n",
    "\n",
    "writer = SummaryWriter(comment='test_your_comment',\n",
    "                       filename_suffix=\"_test_your_filename_suffix\")\n",
    "\n",
    "# 数据\n",
    "path_img = \"./lena.png\"  # your path to image\n",
    "normMean = [0.49139968, 0.48215827, 0.44653124]\n",
    "normStd = [0.24703233, 0.24348505, 0.26158768]\n",
    "\n",
    "norm_transform = transforms.Normalize(normMean, normStd)\n",
    "img_transforms = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(), norm_transform])\n",
    "\n",
    "img_pil = Image.open(path_img).convert('RGB')\n",
    "if img_transforms is not None:\n",
    "    img_tensor = img_transforms(img_pil)\n",
    "img_tensor.unsqueeze_(0)  # chw --> bchw\n",
    "\n",
    "# 模型\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "# 注册hook\n",
    "# 创建一个fature_map字典\n",
    "fmap_dict = dict()\n",
    "for name, sub_module in alexnet.named_modules(): # named_modules() 以字典形式返回特征层名以及特征层信息\n",
    "\n",
    "    if isinstance(sub_module, nn.Conv2d):\n",
    "        key_name = str(sub_module.weight.shape)\n",
    "        fmap_dict.setdefault(key_name, list())\n",
    "\n",
    "        n1, n2 = name.split(\".\")\n",
    "        \n",
    "        # 注册hook函数\n",
    "        def hook_func(m, i, o):\n",
    "            key_name = str(m.weight.shape) # m表示卷积层\n",
    "            fmap_dict[key_name].append(o)  # o表示卷积输出结果\n",
    "\n",
    "        alexnet._modules[n1]._modules[n2].register_forward_hook(hook_func)\n",
    "\n",
    "# forward\n",
    "output = alexnet(img_tensor)\n",
    "\n",
    "# add image\n",
    "for layer_name, fmap_list in fmap_dict.items():\n",
    "    fmap = fmap_list[0]\n",
    "    fmap.transpose_(0, 1)\n",
    "\n",
    "    nrow = int(np.sqrt(fmap.shape[0]))\n",
    "    fmap_grid = vutils.make_grid(fmap,\n",
    "                                 normalize=True,\n",
    "                                 scale_each=True,\n",
    "                                 nrow=nrow)\n",
    "    writer.add_image('feature map in {}'.format(layer_name),\n",
    "                     fmap_grid,\n",
    "                     global_step=322)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码示例：生成特征图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "\n",
    "\n",
    "class CNNLayerVisualization():\n",
    "    \"\"\"\n",
    "        Produces an image that minimizes the loss of a convolution\n",
    "        operation for a specific layer and filter\n",
    "    \"\"\"\n",
    "    def __init__(self, model, selected_layer, selected_filter):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.selected_layer = selected_layer\n",
    "        self.selected_filter = selected_filter\n",
    "        self.conv_output = 0\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('../generated'):\n",
    "            os.makedirs('../generated')\n",
    "\n",
    "    def hook_layer(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            # Gets the conv output of the selected filter (from selected layer)\n",
    "            self.conv_output = grad_out[0, self.selected_filter]\n",
    "        # Hook the selected layer\n",
    "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
    "\n",
    "    def visualise_layer_with_hooks(self):\n",
    "        # Hook the selected layer\n",
    "        self.hook_layer()\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                # x is not used after this point because it is only needed to trigger\n",
    "                # the forward hook function\n",
    "                x = layer(x)\n",
    "                # Only need to forward until the selected layer is reached\n",
    "                if index == self.selected_layer:\n",
    "                    # (forward hook function triggered)\n",
    "                    break\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "\n",
    "    def visualise_layer_without_hooks(self):\n",
    "        # Process image and return variable\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 3)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                x = layer(x)\n",
    "                if index == self.selected_layer:\n",
    "                    # Only need to forward until the selected layer is reached\n",
    "                    # Now, x is the output of the selected layer\n",
    "                    break\n",
    "            # Here, we get the specific filter from the output of the convolution operation\n",
    "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
    "            # So there are 512 unique filter outputs\n",
    "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
    "            # a tensor of shape 28x28\n",
    "            self.conv_output = x[0, self.selected_filter]\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image)\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cnn_layer = 17\n",
    "    filter_pos = 5\n",
    "    # Fully connected layer is not needed\n",
    "    pretrained_model = models.vgg16(pretrained=True).features\n",
    "    layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
    "\n",
    "    # Layer visualization with pytorch hooks\n",
    "    layer_vis.visualise_layer_with_hooks()\n",
    "\n",
    "    # Layer visualization without pytorch hooks\n",
    "    # layer_vis.visualise_layer_without_hooks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CAM and Grad_CAM验证卷积神经网络的注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CAM**\n",
    "\n",
    "- 含有全局池化层的特征图可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](./CAM.jpg)\n",
    "\n",
    "**CAM原理**\n",
    "\n",
    "- 将所有特征图进行全局池化，接全连接层，对于每一类的全连接层所有神经元权重与对应特征图进行相乘获取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T14:43:11.629821Z",
     "start_time": "2020-05-05T14:43:11.624825Z"
    }
   },
   "source": [
    "**Grad_CAM**\n",
    "\n",
    "- 利用梯度值作为特征图进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
