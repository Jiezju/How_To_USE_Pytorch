{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:41:51.177455Z",
     "start_time": "2020-04-14T12:41:51.172465Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:40:23.308244Z",
     "start_time": "2020-04-14T12:40:23.300265Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "模型定义\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义权值初始化\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T12:41:57.647372Z",
     "start_time": "2020-04-14T12:41:57.627426Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, txt_path, transform = None, target_transform = None):\n",
    "        fh = open(txt_path, 'r')\n",
    "        imgs = []\n",
    "        for line in fh:\n",
    "            line = line.rstrip()\n",
    "            words = line.split()\n",
    "            imgs.append((words[0], int(words[1])))\n",
    "\n",
    "        self.imgs = imgs        # 最主要就是要生成这个list， 然后DataLoader中给index，通过getitem读取图片数据\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        img = Image.open(fn).convert('RGB')     # 像素值 0~255，在transfrom.totensor会除以255，使像素值变成 0~1\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)   # 在这里做transform，转为tensor等等\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "def validate(net, data_loader, set_name, classes_name):\n",
    "    \"\"\"\n",
    "    对一批数据进行预测，返回混淆矩阵以及Accuracy\n",
    "    :param net:\n",
    "    :param data_loader:\n",
    "    :param set_name:  eg: 'valid' 'train' 'tesst\n",
    "    :param classes_name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    cls_num = len(classes_name)\n",
    "    conf_mat = np.zeros([cls_num, cls_num])\n",
    "\n",
    "    for data in data_loader:\n",
    "        images, labels = data\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "\n",
    "        outputs = net(images)\n",
    "        outputs.detach_()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 统计混淆矩阵\n",
    "        for i in range(len(labels)):\n",
    "            cate_i = labels[i].numpy()\n",
    "            pre_i = predicted[i].numpy()\n",
    "            conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "    for i in range(cls_num):\n",
    "        print('class:{:<10}, total num:{:<6}, correct num:{:<5}  Recall: {:.2%} Precision: {:.2%}'.format(\n",
    "            classes_name[i], np.sum(conf_mat[i, :]), conf_mat[i, i], conf_mat[i, i] / (1 + np.sum(conf_mat[i, :])),\n",
    "                                                                conf_mat[i, i] / (1 + np.sum(conf_mat[:, i]))))\n",
    "\n",
    "    print('{} set Accuracy:{:.2%}'.format(set_name, np.trace(conf_mat) / np.sum(conf_mat)))\n",
    "\n",
    "    return conf_mat, '{:.2}'.format(np.trace(conf_mat) / np.sum(conf_mat))\n",
    "\n",
    "\n",
    "def show_confMat(confusion_mat, classes, set_name, out_dir):\n",
    "\n",
    "    # 归一化\n",
    "    confusion_mat_N = confusion_mat.copy()\n",
    "    for i in range(len(classes)):\n",
    "        confusion_mat_N[i, :] = confusion_mat[i, :] / confusion_mat[i, :].sum()\n",
    "\n",
    "    # 获取颜色\n",
    "    cmap = plt.cm.get_cmap('Greys')  # 更多颜色: http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "    plt.imshow(confusion_mat_N, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # 设置文字\n",
    "    xlocations = np.array(range(len(classes)))\n",
    "    plt.xticks(xlocations, list(classes), rotation=60)\n",
    "    plt.yticks(xlocations, list(classes))\n",
    "    plt.xlabel('Predict label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.title('Confusion_Matrix_' + set_name)\n",
    "\n",
    "    # 打印数字\n",
    "    for i in range(confusion_mat_N.shape[0]):\n",
    "        for j in range(confusion_mat_N.shape[1]):\n",
    "            plt.text(x=j, y=i, s=int(confusion_mat[i, j]), va='center', ha='center', color='red', fontsize=10)\n",
    "    # 保存\n",
    "    plt.savefig(os.path.join(out_dir, 'Confusion_Matrix' + set_name + '.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def normalize_invert(tensor, mean, std):\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.mul_(s).add_(m)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt_path = os.path.join(\"..\", \"..\", \"Data\", \"train.txt\")\n",
    "valid_txt_path = os.path.join(\"..\", \"..\", \"Data\", \"valid.txt\")\n",
    "\n",
    "classes_name = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "train_bs = 16\n",
    "valid_bs = 16\n",
    "lr_init = 0.001\n",
    "max_epoch = 1\n",
    "\n",
    "# log\n",
    "result_dir = os.path.join(\"..\", \"..\", \"Result\")\n",
    "\n",
    "now_time = datetime.now()\n",
    "time_str = datetime.strftime(now_time, '%m-%d_%H-%M-%S')\n",
    "\n",
    "log_dir = os.path.join(result_dir, time_str)\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# ------------------------------------ step 1/5 : 加载数据------------------------------------\n",
    "\n",
    "# 数据预处理设置\n",
    "normMean = [0.4948052, 0.48568845, 0.44682974]\n",
    "normStd = [0.24580306, 0.24236229, 0.2603115]\n",
    "normTransform = transforms.Normalize(normMean, normStd)\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "validTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normTransform\n",
    "])\n",
    "\n",
    "# 构建MyDataset实例\n",
    "train_data = MyDataset(txt_path=train_txt_path, transform=trainTransform)\n",
    "valid_data = MyDataset(txt_path=valid_txt_path, transform=validTransform)\n",
    "\n",
    "# 构建DataLoder\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=train_bs, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=valid_bs)\n",
    "\n",
    "# ------------------------------------ step 2/5 : 定义网络------------------------------------\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # 定义权值初始化\n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                torch.nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                torch.nn.init.normal_(m.weight.data, 0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "net = Net()     # 创建一个网络\n",
    "net.initialize_weights()    # 初始化权值\n",
    "\n",
    "# ------------------------------------ step 3/5 : 定义损失函数和优化器 ------------------------------------\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()                                                   # 选择损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr_init, momentum=0.9, dampening=0.1)    # 选择优化器\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)     # 设置学习率下降策略\n",
    "\n",
    "# ------------------------------------ step 4/5 : 训练 --------------------------------------------------\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    loss_sigma = 0.0    # 记录一个epoch的loss之和\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    scheduler.step()  # 更新学习率\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # if i == 30 : break\n",
    "        # 获取图片和标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward, backward, update weights\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).squeeze().sum().numpy()\n",
    "        loss_sigma += loss.item()\n",
    "\n",
    "        # 每10个iteration 打印一次训练信息，loss为10个iteration的平均\n",
    "        if i % 10 == 9:\n",
    "            loss_avg = loss_sigma / 10\n",
    "            loss_sigma = 0.0\n",
    "            print(\"Training: Epoch[{:0>3}/{:0>3}] Iteration[{:0>3}/{:0>3}] Loss: {:.4f} Acc:{:.2%}\".format(\n",
    "                epoch + 1, max_epoch, i + 1, len(train_loader), loss_avg, correct / total))\n",
    "\n",
    "            # 记录训练loss\n",
    "            writer.add_scalars('Loss_group', {'train_loss': loss_avg}, epoch)\n",
    "            # 记录learning rate\n",
    "            writer.add_scalar('learning rate', scheduler.get_lr()[0], epoch)\n",
    "            # 记录Accuracy\n",
    "            writer.add_scalars('Accuracy_group', {'train_acc': correct / total}, epoch)\n",
    "\n",
    "    # 每个epoch，记录梯度，权值\n",
    "    for name, layer in net.named_parameters():\n",
    "        writer.add_histogram(name + '_grad', layer.grad.cpu().data.numpy(), epoch)\n",
    "        writer.add_histogram(name + '_data', layer.cpu().data.numpy(), epoch)\n",
    "\n",
    "    # ------------------------------------ 观察模型在验证集上的表现 ------------------------------------\n",
    "    if epoch % 2 == 0:\n",
    "        loss_sigma = 0.0\n",
    "        cls_num = len(classes_name)\n",
    "        conf_mat = np.zeros([cls_num, cls_num])  # 混淆矩阵\n",
    "        net.eval()\n",
    "        for i, data in enumerate(valid_loader):\n",
    "\n",
    "            # 获取图片和标签\n",
    "            images, labels = data\n",
    "            images, labels = Variable(images), Variable(labels)\n",
    "\n",
    "            # forward\n",
    "            outputs = net(images)\n",
    "            outputs.detach_()\n",
    "\n",
    "            # 计算loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss_sigma += loss.item()\n",
    "\n",
    "            # 统计\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # labels = labels.data    # Variable --> tensor\n",
    "\n",
    "            # 统计混淆矩阵\n",
    "            for j in range(len(labels)):\n",
    "                cate_i = labels[j].numpy()\n",
    "                pre_i = predicted[j].numpy()\n",
    "                conf_mat[cate_i, pre_i] += 1.0\n",
    "\n",
    "        print('{} set Accuracy:{:.2%}'.format('Valid', conf_mat.trace() / conf_mat.sum()))\n",
    "        # 记录Loss, accuracy\n",
    "        writer.add_scalars('Loss_group', {'valid_loss': loss_sigma / len(valid_loader)}, epoch)\n",
    "        writer.add_scalars('Accuracy_group', {'valid_acc': conf_mat.trace() / conf_mat.sum()}, epoch)\n",
    "print('Finished Training')\n",
    "\n",
    "# ------------------------------------ step5: 保存模型 并且绘制混淆矩阵图 ------------------------------------\n",
    "net_save_path = os.path.join(log_dir, 'net_params.pkl')\n",
    "torch.save(net.state_dict(), net_save_path)\n",
    "\n",
    "conf_mat_train, train_acc = validate(net, train_loader, 'train', classes_name)\n",
    "conf_mat_valid, valid_acc = validate(net, valid_loader, 'valid', classes_name)\n",
    "\n",
    "show_confMat(conf_mat_train, classes_name, 'train', log_dir)\n",
    "show_confMat(conf_mat_valid, classes_name, 'valid', log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
